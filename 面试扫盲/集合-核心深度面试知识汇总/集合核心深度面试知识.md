# 集合核心深度面试知识

> 声明：此内容来自B站大佬：==河北王校长==

#### 31、介绍下JDK1.7的ConcurrentHashMap的数据结构

ConcurrentHashMap和HashMap思路是差不多的，但是因为它支持并发操作，所以更复杂一些。

整个ConcurrentHashMap由一个个Segment组成，Segment代表“部分”或“分段”的意思，很多地方都将其描述成为**分段锁**

简单理解就是，ConcurrentHashMap是一个Segment数组，Segment通过继承ReetrantLock来进行加锁，所以每次需要加锁的操作锁住的是一个Segment，通过保证每个Segment是线程安全的，也就实现了全局的线程安全。



#### 32、ConcurrentHashMap的构造方法有几个？

```java
// 无参构造
public ConcurrentHashMap() {
}

// 可传初始容器大小的构造函数
public ConcurrentHashMap(int initialCapacity) {
    if (initialCapacity < 0)
        throw new IllegalArgumentException();
    int cap = ((initialCapacity >= (MAXIMUM_CAPACITY >>> 1)) ?
               MAXIMUM_CAPACITY :
               tableSizeFor(initialCapacity + (initialCapacity >>> 1) + 1));
    this.sizeCtl = cap;
}

// 可传Map的构造函数
public ConcurrentHashMap(Map<? extends K, ? extends V> m) {
    this.sizeCtl = DEFAULT_CAPACITY;
    putAll(m);
}

// 可设置阈值和初始容量
public ConcurrentHashMap(int initialCapacity, float loadFactor) {
    this(initialCapacity, loadFactor, 1);
}

// 可设置初始容量和阈值和并发级别
public ConcurrentHashMap(int initialCapacity,
                         float loadFactor, int concurrencyLevel) {
    if (!(loadFactor > 0.0f) || initialCapacity < 0 || concurrencyLevel <= 0)
        throw new IllegalArgumentException();
    if (initialCapacity < concurrencyLevel)   // Use at least as many bins
        initialCapacity = concurrencyLevel;   // as estimated threads
    long size = (long)(1.0 + (long)initialCapacity / loadFactor);
    int cap = (size >= (long)MAXIMUM_CAPACITY) ?
        MAXIMUM_CAPACITY : tableSizeFor((int)size);
    this.sizeCtl = cap;
}
```

`concurrencyLevel`：并行级别、并发数、Segment数、怎么翻译不重要，要理解。默认值是16，也就是说ConcurrentHashMap有16个Segments。

所以理论上，这个时候，最多可以同时支持16个线程并发写，只要它们的操作分别分布在不同的Segment上。这个值可以在初始化的时候设置为其他值，但是一旦初始化后，是不可以扩容的。

再具体到每个Segment内部，其实每个Segment很像之前介绍的HashMap，不过它要保证线程安全，所以处理起来要麻烦些。



#### 33、简述JDK1.7下CurrentHashMap是如何进行锁操作的

JDK1.7 是采用 ReetrantLock + Segment + HashEntry。写操作的时候可以只对元素所在的Segment进行加锁即可，不会影响到其他的Segment，这样，在最理想的情况下。ConcurrentHashMap可以最高同时支持Segment数量大小的写操作。

```java
// HashEntry ： 用来存储元素
static class HashEntry<K,V>{
    final int hash;
    final K key;
    volatile V val;
    volatile HashEntry<K,V> next;

    HashEntry(int hash, K key, V val, HashEntry<K,V> next) {
        this.hash = hash;
        this.key = key;
        this.val = val;
        this.next = next;
    }
    
// Segment桶：实现线程的关键类（部分属性未列出，太长）
static final class Segment<K,V> extends ReetrantLock implements Serializable{
    // Segment继承自ReetrantLock，是一个天然的锁
    transient volatile HashEntry<K,V>[] table;
    // ....
    transient int count;
}
```

#### 34、JDK1.8的CurrentHashMap是如何保证并发的

JDK1.8中，ConcurrentHashMap参考了JDK1.8 HashMap的实现。采用了数组+链表+红黑树的实现方式来设计，内部大量采用CAS操作。

简要介绍下CAS

CAS是compare and swap的缩写，即我们所说的比较并交换。CAS是注一种基于锁的操作，而且是乐观锁。在java中锁分为乐观锁和悲观锁。悲观锁是将资源锁住，等前一个获得锁的线程释放锁之后，下一个线程才可以访问。而乐观锁采取了一种宽泛的态度，通过某种方式不加锁来处理资源，比如通过给记录添加version来获取数据，性能较于 悲观锁来说有很大提高。

JDK8中彻底放弃了Segment转而采用的是Node，其设计思想也不再是JDK7中的分段锁思想。

Node：保存key，value以及key的hash值得数据结构，其中value和next都是使用volatile修饰，保证并发可见性。

JDK8 ConcurrentHashMap结构基本上和JDK8得HashMap一样，不过保证线程安全性。

```java
// 存储节点
static class Node<K,V> implements Map.Entry<K,V> {
    final int hash;
    final K key;
    volatile V val;
    volatile Node<K,V> next;

    Node(int hash, K key, V val, Node<K,V> next) {
        this.hash = hash;
        this.key = key;
        this.val = val;
        this.next = next;
    }
```

```java
// jdk1.8取消了桶得设计，使用了node+cas+synchronized来保证并发安全
final V putVal(K key, V value, boolean onlyIfAbsent) {
    if (key == null || value == null) throw new NullPointerException();
    int hash = spread(key.hashCode());
    int binCount = 0;
    for (Node<K,V>[] tab = table;;) {
        Node<K,V> f; int n, i, fh;
        if (tab == null || (n = tab.length) == 0)
            tab = initTable();  //初始化
        else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) { //如果该位置无元素，则直接放入
            if (casTabAt(tab, i, null,
                         new Node<K,V>(hash, key, value, null)))
                break;                   // no lock when adding to empty bin
        }
        else if ((fh = f.hash) == MOVED)
            tab = helpTransfer(tab, f);
        else {
            V oldVal = null;
            synchronized (f) { //如果有元素cas插入失败，则使用同步锁
                if (tabAt(tab, i) == f) {
                    if (fh >= 0) {
                        binCount = 1;
                        for (Node<K,V> e = f;; ++binCount) {
                            K ek;
                            if (e.hash == hash &&
                                ((ek = e.key) == key ||
                                 (ek != null && key.equals(ek)))) {
                                oldVal = e.val;
                                if (!onlyIfAbsent)
                                    e.val = value;
                                break;
                            }
                            Node<K,V> pred = e;
                            if ((e = e.next) == null) {
                                pred.next = new Node<K,V>(hash, key,
                                                          value, null);
                                break;
                            }
                        }
                    }
                    else if (f instanceof TreeBin) {
                        Node<K,V> p;
                        binCount = 2;
                        if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key,
                                                              value)) != null) {
                            oldVal = p.val;
                            if (!onlyIfAbsent)
                                p.val = value;
                        }
                    }
                }
            }
            if (binCount != 0) {
                if (binCount >= TREEIFY_THRESHOLD)
                    treeifyBin(tab, i);
                if (oldVal != null)
                    return oldVal;
                break;
            }
        }
    }
    addCount(1L, binCount);
    return null;
}
```

#### 35、CurrentHashMap在JDK1.8的改进

其实可以看出JDK1.8版本的CurrentHashMap的数据结构以及接近HashMap，相对而言CurrentHashMap只是增加了同步的操作来控制并发，从JDK1.7版本的`ReentrantLock+Segment+HashEntry`，到JDK1.8版本中`synchronized+CAS+HashEntry`+红黑树。

从下面5个方面来分析：

1、数据结构：取消了Segment分段锁的数据结构,取而代之的是数组+链表+红黑树的结构

2、保证线程安全机制：JDK1.7采用segment的分段锁机制实现线程安全,其中`segment继承自ReentrantLock`。JDK1.8采用`CAS+Synchronized`保证线程安全。

3、锁的粒度：来是对需要进行数据操作的Segment加锁，现调整为对每个数组元素加锁(Node)

4、链表转化为红黑树：定位结点的hash算法简化会带来弊端，hash冲突加剧，因此在链表节点数量>8时，会将链表转化成红黑树进行存储。

5、查询时间复杂度：从原来的遍历链表O(n)，变成遍历红黑树O(logN)

