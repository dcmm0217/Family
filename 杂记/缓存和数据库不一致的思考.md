# 对于缓存和数据库不一致的思考

### 1、为什么会出现不一致?

当我们访问某热点数据时，使用缓存可以提高接口的QPS，但是如果此时

- 修改数据库，但是没有去操作缓存，短时间内缓存又不会过期。

- 修改数据库，去删除缓存，但是删除失败了，缓存没过期。

就会出现缓存和数据库数据不一致的情况

这是日常开发中非常常见的一种问题。下面我们尝试对其探讨一下



### 2、谈谈一致性

一致性就就是保持数据的一致，在分布式系统中，可以理解为多个节点中数据的值是一致的。

- **强一致性：**这种一致性级别是最符合用户直觉的，即是系统写入什么，读出来的也会是什么，用户体验好，但是实现起来往往难度比较大，而且对系统的性能影响大
- **弱一致性：**这种一致性级别约束了系统在写入成功后，不承诺立即可以读到写入的值，也不承诺多久后能达到一致，但是会尽可能的保证到某个时间级别后，数据能够到达一致状态
- **最终一致性：**最终一致性是弱一致性的一个特例，系统会保证在一定时间内，能够达到一个数据一致的状态。提出最终一致性是因为它是弱一致性种非常推崇的一种一致性模型，也是**业界内大型分布式系统中数据一致性上比较推荐的模型**



### 3、三个经典的缓存模式

缓存可以提升性能、缓解数据库压力，但是使用缓存也会导致**数据不一致**的问题。一般我们是如何使用缓存的呢？

有三种经典的缓存模式：

- Cahche-Aside Pattern
- Read-Through/Write through
- Write behind

#### Cache-Aside Pattern

Cache-Aside Pattern，即**旁路缓存模式**，它的提出是为了尽可能的解决缓存与数据库得到不一致问题。

**Cache-Aside读流程**

**Cache-Aside Pattern**的读请求流程如下：

![image-20211123235713234](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/img/image-20211123235713234.png)

1、读的时候，先去读缓存，缓存命中，直接返回数据

2、缓存没有命中，就去读数据库，从数据库读出数据，放入缓存，同时返回响应

```java
@GetMapping(value = "/get")
@ResponseBody
public CommonReturnType getItem(@RequestParam("id")Integer id){
    //多级缓存 优化访问策略   1、本地缓存  2、redis缓存 3、数据库
    ItemModel itemById = null;
    //本地缓存
    itemById = (ItemModel) cacheService.getFromCommonCache("item_"+id);
    if (itemById==null){
        // redis缓存
        itemById = (ItemModel) redisTemplate.opsForValue().get("item_" + id);
        if (itemById==null){
            // 数据库
            itemById = itemService.getItemById(id);
            // 设置redis缓存
            redisTemplate.opsForValue().set("item_"+id,itemById,10, TimeUnit.MINUTES);
        }
        // 设置本地缓存
        cacheService.setCommonCache("item_"+id,itemById);
    }
    ItemVO itemVO = convertVOFromModel(itemById);
    return CommonReturnType.create(itemVO);
}
```

**Cache-Aside 写流程**

**Cache-Aside Pattern**的写请求流程如下：

![image-20211124000323014](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/img/image-20211124000323014.png)

更新的时候，先**更新数据库，然后再删除缓存**。

```java
@PostMapping(value = "/update",consumes = {CONTENT_TYPE_FORMED})
@ResponseBody
public CommonReturnType updateItem(@RequestParam(name = "title") String title,
                                   @RequestParam(name = "description") String description,
                                   @RequestParam(name = "price") BigDecimal price,
                                   @RequestParam(name = "stock") Integer stock,
                                   @RequestParam(name = "imgUrl") String imgUrl,
                                   @RequestParam(name = "id")Integer id) throws BusinessException {
    //封装service请求用来创建商品
    ItemModel itemModel = itemService.getItemById(id);
    itemModel.setDescription(description);
    itemModel.setStock(stock);
    itemModel.setPrice(price);
    itemModel.setImgUrl(imgUrl);
    itemModel.setTitle(title);
	// 更新数据库
    ItemModel itemModelForReturn = itemService.updateItem(itemModel);
    // 删除本地缓存
    cacheService.deleteCommonCache("item_" + id);
    // 删除redis缓存
    redisTemplate.delete("item_" + id);
    
    ItemVO itemVO = convertVOFromModel(itemModelForReturn);
    return CommonReturnType.create(itemVO);
}
```



#### Read-Through/Write-Through（读写穿透）

**Read/Write Through**模式中，服务端把缓存作为主要数据存储。应用程序跟数据库缓存交互，都是通过**抽象缓存层**完成的。

**Read-Through**

**Read-Through**的简要流程如下

![image-20211124001428024](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/img/image-20211124001428024.png)

1、从缓存读取数据，读到直接返回

2、如果读取不到的话，从数据库加载，写入缓存后，再返回响应。

这个简要流程是不是跟**Cache-Aside**很像？其实**Read-Through**就是多了一层**Cache-Provider**，流程如下：

![image-20211124001508406](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/img/image-20211124001508406.png)

Read-Through实际只是在**Cache-Aside**之上进行了一层封装，它会让程序代码变得更简洁，同时也减少数据源上的负载。

**Write-Through**

**Write-Through**模式下，当发生写请求时，也是由**缓存抽象层**完成数据源和缓存数据的更新,流程如下：

![image-20211124001530005](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/img/image-20211124001530005.png)

#### Write behind （异步缓存写入）

**Write behind**跟**Read-Through/Write-Through**有相似的地方都是由`Cache Provider`来负责缓存和数据库的读写。它两又有个很大的不同：**Read/Write Through**是同步更新缓存和数据的，**Write Behind**则是只更新缓存，不直接更新数据库，通过**批量异步**的方式来更新数据库。

![image-20211124001600496](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/img/image-20211124001600496.png)

这种方式下，缓存和数据库的一致性不强，**对一致性要求高的系统要谨慎使用**。但是它适合频繁写的场景，MySQL的**InnoDB Buffer Pool机制**就使用到这种模式。

### 4、操作缓存的时候，删除缓存呢，还是更新缓存？

一般业务场景，我们使用的就是**Cache-Aside**模式。 有些小伙伴可能会问， **Cache-Aside**在写入请求的时候，为什么是**删除缓存而不是更新缓存**呢？

![image-20211124001700874](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/img/image-20211124001700874.png)

我们在操作缓存的时候，到底应该删除缓存还是更新缓存呢？我们先来看个例子：

![image-20211124001720797](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/img/image-20211124001720797.png)

1、线程A先发起一个写操作，第一步先更新数据库

2、线程B再发起一个写操作，第二步更新了数据库

3、由于网络等原因，线程B先更新了缓存

4、线程A更新缓存。

这时候，缓存保存的是A的数据（老数据），数据库保存的是B的数据（新数据），数据**不一致**了，脏数据出现。如果是**删除缓存取代更新缓存**则不会出现这个脏数据问题。

**更新缓存相对于删除缓存**，还有两点劣势：

- 如果你写入的缓存值，是经过复杂计算才得到的话。更新缓存频率高的话，就浪费性能。
- 在写数据库场景多，读数据场景少的情况下，数据很多时候还没被读取到，又被更新了，这也浪费了性能呢(实际上，写多的场景，用缓存也不是很划算了)

### 5、双写的情况下，先操作数据库还是先操作缓存？

`Cache-Aside`缓存模式中，有些小伙伴还是有疑问，在写入请求的时候，为什么是**先操作数据库呢**？为什么**不先操作缓存**呢？

假设有A、B两个请求，请求A做更新操作，请求B做查询读取操作。

![image-20211124001816288](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/img/image-20211124001816288.png)

1、线程A发起一个写操作，第一步del cache

2、此时线程B发起一个读操作，cache miss

3、线程B继续读DB，读出来一个老数据

4、然后线程B把老数据设置入cache

5、线程A写入DB最新的数据

有问题，**缓存和数据库的数据不一致了。缓存保存的是老数据，数据库保存的是新数据**。因此，`Cache-Aside`缓存模式，选择了先操作数据库而不是先操作缓存。

### 6、缓存延时双删

有些小伙伴可能会说，不一定要先操作数据库呀，采用**缓存延时双删**策略就好啦？什么是延时双删呢？

![image-20211124001856615](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/img/image-20211124001856615.png)

1、先删除缓存

2、再更新数据库

3、休眠一会（比如1秒），再次删除缓存。

这个休眠一会，一般多久呢？都是1秒？

> 这个休眠时间 = 读业务逻辑数据的耗时 + 几百毫秒。 为了确保读请求结束，写请求可以删除读请求可能带来的缓存脏数据。

**第一个问题**，还记得前面讲到的「先删除缓存，再更新数据库」方案，导致不一致的场景么？

这里我再把例子拿过来让你复习一下：

2 个线程要并发「读写」数据，可能会发生以下场景：

1. 线程 A 要更新 X = 2（原值 X = 1）
2. 线程 A 先删除缓存
3. 线程 B 读缓存，发现不存在，从数据库中读取到旧值（X = 1）
4. 线程 A 将新值写入数据库（X = 2）
5. 线程 B 将旧值写入缓存（X = 1）

最终 X 的值在缓存中是 1（旧值），在数据库中是 2（新值），发生不一致。

**第二个问题**：是关于「读写分离 + 主从复制延迟」情况下，缓存和数据库一致性的问题。

在「先更新数据库，再删除缓存」方案下，「读写分离 + 主从库延迟」其实也会导致不一致：

1. 线程 A 更新主库 X = 2（原值 X = 1）
2. 线程 A 删除缓存
3. 线程 B 查询缓存，没有命中，查询「从库」得到旧值（从库 X = 1）
4. 从库「同步」完成（主从库 X = 2）
5. 线程 B 将「旧值」写入缓存（X = 1）

最终 X 的值在缓存中是 1（旧值），在主从库中是 2（新值），也发生不一致。

看到了么？这 2 个问题的核心在于：**缓存都被回种了「旧值」**。

那怎么解决这类问题呢？

最有效的办法就是，**把缓存删掉**。

但是，不能立即删，而是需要「延迟删」，这就是业界给出的方案：**缓存延迟双删策略**。

按照`延迟双删策略`，这2个问题的解决方案是这样的：

**解决第一个问题：**

在线程A删除缓存、更新完数据库后，先休眠一会，再[删除]缓存

**解决第二的问题：**

线程A生成一条[延时消息]，写到消息队列中，消费者延时[删除]缓存，**即在更新主库成功并且将数据同步到从库后删除缓存**。

这两个方案的目的，都是为了把缓存清掉，这样一来，下次就可以从数据库读取到最新值，写入缓存。

但问题来了，这个「**延迟删除」缓存，延迟时间到底设置要多久呢**？

- 问题1：**延迟时间要大于「主从复制」的延迟时间**
- 问题2：**延迟时间要大于线程 B 读取数据库 + 写入缓存的时间**

但是，**这个时间在分布式和高并发场景下，其实是很难评估的****。**

很多时候，我们都是凭借经验大致估算这个延迟时间，**例如延迟 1-5s**，只能尽可能地降低不一致的概率。

所以你看，采用这种方案，也只是尽可能保证一致性而已，极端情况下，还是有可能发生不一致。

**==所以实际使用中，我还是建议你采用「先更新数据库，再删除缓存」的方案，同时，要尽可能地保证「主从复制」不要有太大延迟，降低出问题的概率。==**

### 7、删除缓存重试机制

不管是**延时双删**还是**Cache-Aside的先操作数据库再删除缓存**，如果第二步的删除缓存失败呢，删除失败会导致脏数据哦~

> 删除失败就多删除几次，保证删除缓存成功呀~ 所以可以引入**删除缓存重试机制**

![image-20211124001949965](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/img/image-20211124001949965.png)

1、写请求更新数据库

2、缓存因为某些原因，删除失败

3、把删除失败的key放到消息队列

4、消费消息队列的消息，获取要删除的key

5、重试删除缓存操作

### 8、读取biglog异步删除缓存

重试删除缓存机制还可以，就是会造成好多业务代码入侵。其实，还可以通过**数据库的binlog来异步淘汰key**。

![image-20211124002031656](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/img/image-20211124002031656.png)

以mysql为例 可以使用阿里的canal将binlog日志采集发送到MQ队列里面，然后通过ACK机制确认处理这条更新消息，删除缓存，保证数据缓存一致性