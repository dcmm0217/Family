# 第3节-读写分离 + 分库分表实现原理

## 1、搭建主从同步数据库  

- 主从同步原理  

Master将数据写⼊到binlog⽇志中。 Slave读取主节点的binlog数据到本地的relaylog(中继日志)⽇志⽂件中。此时， Slave持续不断的与Master同步，且数据存在于relaylog中，⽽并⾮落在数据库。于是Slave开启⼀条线程，专⻔讲relaylog中的数据写⼊到数据库中。 

![image-20220822231455921](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220822231455921.png)

- 准备Master主库

```yml
version: '3.1'
	services:
		mysql:
		restart: always
		image: mysql:5.7.25
		container_name: mysql
		ports:
			- 3306:3306
		environment:
		TZ: Asia/Shanghai
		MYSQL_ROOT_PASSWORD: 123456
	command:
	--character-set-server=utf8mb4
	--collation-server=utf8mb4_general_ci
	--explicit_defaults_for_timestamp=true
	--lower_case_table_names=1
	--max_allowed_packet=128M
	--server-id=47
	--log_bin=master-bin
	--log_bin-index=master-bin.index
	--skip-name-resolve
	--sql-mode="STRICT_TRANS_TABLES,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION,NO_ZERO_DATE,NO_ZERO_IN_DATE,ERROR_FOR_DIVISION_BY_ZERO"
	volumes:
		- mysql-data:/var/lib/mysq
volumes:
	mysql-data:
```

注意其中的配置：  

```
服务id： server-id=47
开启binlog： log_bin=master-bin
binlog索引： log_bin-index=master-bin.index
```

通过 show master status 命令查看并记录⽂件名和偏移量。  

![image-20220822233809651](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220822233809651.png)

- 准备Slave从库：  

```yml
version: '3.1'
	services:
		mysql:
		restart: always
		image: mysql:5.7.25
		container_name: mysql
		ports:
			- 3306:3306
		environment:
		TZ: Asia/Shanghai
		MYSQL_ROOT_PASSWORD: 123456
	command:
	--character-set-server=utf8mb4
	--collation-server=utf8mb4_general_ci
	--explicit_defaults_for_timestamp=true
	--lower_case_table_names=1
	--max_allowed_packet=128M
	--server-id=48
	--relay-log-index=slave-relay-bin.index
	--relay-log=slave-relay-bin
	--log_bin=mysql-bin
	--log-slave-updates=1
	--sql-mode="STRICT_TRANS_TABLES,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION,NO_ZERO_DATE,NO_ZERO_IN_DATE,ERROR_FOR_DIVISION_BY_ZERO"
	volumes:
		- mysql-data:/var/lib/mysq
volumes:
	mysql-data:
```

注意其中的关键配置：  

```
服务id： server-id=48
开启中继⽇志： relay-log-index=slave-relay-bin.index
开启中继⽇志： relay-log=slave-relay-bin
```

启动从库后进⼊到从库，并依次执⾏如下命令：  

```ini
#登录从服务
mysql -u root -p;
#设置同步主节点：
CHANGE MASTER TO
MASTER_HOST='172.16.253.31',
MASTER_PORT=3306,
MASTER_USER='root',
MASTER_PASSWORD='123456',
MASTER_LOG_FILE='master-bin.000003',
MASTER_LOG_POS=154;
#开启slave
start slave;
```

⾄此，主从同步集群搭建完成。  

在主库中创建 `db_device` 数据库，并在库中创建表：  

```sql
CREATE TABLE `tb_user` (
    `id` bigint(20) NOT NULL AUTO_INCREMENT,
    `name` varchar(255) DEFAULT NULL,
    PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=4 DEFAULT CHARSET=utf8mb4;
```

## 2、使用Sharding-jdbc实现读写分离

- 编写配置⽂件  

```properties
# 配置真实数据源
spring.shardingsphere.datasource.names=m0,s0
# 配置主数据源
spring.shardingsphere.datasource.m0.type=com.alibaba.druid.pool.DruidDa
taSource
spring.shardingsphere.datasource.m0.driver-classname=com.mysql.cj.jdbc.Driver
spring.shardingsphere.datasource.m0.url=jdbc:mysql://172.16.253.73:3306/db_device?serverTimezone=Asia/Shanghai
spring.shardingsphere.datasource.m0.username=root
spring.shardingsphere.datasource.m0.password=123456

# 配置从数据源
spring.shardingsphere.datasource.s0.type=com.alibaba.druid.pool.DruidDa
taSource
spring.shardingsphere.datasource.s0.driver-classname=com.mysql.cj.jdbc.Driver
spring.shardingsphere.datasource.s0.url=jdbc:mysql://172.16.253.74:3306/db_device?serverTimezone=Asia/Shanghai
spring.shardingsphere.datasource.s0.username=root
spring.shardingsphere.datasource.s0.password=123456

# 分配读写规则
spring.shardingsphere.sharding.master-slave-rules.ds0.master-datasource-name=m0
spring.shardingsphere.sharding.master-slave-rules.ds0.slave-datasource-names[0]=s0

# 确定实际表
spring.shardingsphere.sharding.tables.tb_user.actual-datanodes=ds0.tb_user

# 确定主键⽣成策略
spring.shardingsphere.sharding.tables.t_dict.key-generator.column=id
spring.shardingsphere.sharding.tables.t_dict.keygenerator.type=SNOWFLAKE

# 开启显示sql语句
spring.shardingsphere.props.sql.show = true
```

- 测试写数据  

```java
@Test
void testInsertUser(){
    for (int i = 0; i < 10; i++) {
        TbUser user = new TbUser();
        user.setName(""+i);
        userMapper.insert(user);
    }
}
```

此时，所有的数据只会往主库中写，然后再同步到从库。  

- 测试读数据  

```java
@Test
void testQueryUser(){
    List<TbUser> tbUsers = userMapper.selectList(null);
    tbUsers.forEach( tbUser -> System.out.println(tbUser));
}
```

此时，所有的数据都读⾃于从库。  

## 3、实现原理-连接模式

ShardingSphere 采⽤⼀套==⾃动化的执⾏引擎==，==负责将路由和改写完成之后的真实 SQL 安全且⾼效发送到底层数据源执⾏。==   

它不是简单地将 SQL 通过 JDBC 直接发送⾄数据源执⾏；也并⾮直接将执⾏请求放⼊线程池去并发执⾏。  

它更关注平衡数据源连接创建以及内存占⽤所产⽣的消耗，以及最⼤限度地合理利⽤并发等问题。  执⾏引擎的⽬标是⾃动化的平衡资源控制与执⾏效率。  

#### 3.1 连接模式  

**从资源控制的⻆度看**，业务⽅访问数据库的连接数量应当有所限制。 它能够有效地防⽌某⼀业务操作过多的占⽤资源，从⽽将数据库连接的资源耗尽，以致于影响其他业务的正常访问。   

特别是在⼀个数据库实例中存在较多分表的情况下，==⼀条不包含分⽚键的逻辑 SQL 将产⽣落在同库不同表的⼤量真实 SQL ，如果每条真实SQL都占⽤⼀个独⽴的连接，那么⼀次查询⽆疑将会占⽤过多的资源。==  

**从执⾏效率的⻆度看** ，为每个分⽚查询维持⼀个独⽴的数据库连接，可以更加有效的利⽤多线程来提升执⾏效率。  为每个数据库连接开启独⽴的线程，可以将 I/O 所产⽣的消耗并⾏处理。为每个分⽚维持⼀个独⽴的数据库连接，还能够避免过早的将查询结果数据加载⾄内存。独⽴的数据库连接，能够持有查询结果集游标位置的引⽤，在需要获取相应数据时移动游标即可。    

==以结果集游标下移进⾏结果归并的⽅式，称之为流式归并==  ，它⽆需将结果数据全数加载⾄内存，可以有效的节省内存资源，进⽽减少垃圾回收的频次。当⽆法保证每个分⽚查询持有⼀个独⽴数据库连接时，则需要在复⽤该数据库连接获取下⼀张分表的查询结果集之前，将当前的查询结果集全数加载⾄内存。因此，即使可以采⽤流式归并，在此场景下也将退化为内存归并。       

⼀⽅⾯是对数据库连接资源的控制保护，⼀⽅⾯是采⽤更优的归并模式达到对中间件内存资源的节省，如何处理好两者之间的关系  ，是 ShardingSphere 执⾏引擎需要解决的问题。  

具体来说，如果⼀条 SQL 在经过 ShardingSphere 的分⽚后，需要操作某数据库实例下的 200张表。 

==那么，是选择创建 200 个连接并⾏执⾏，还是选择创建⼀个连接串⾏执⾏呢？效率与资源控制⼜应该如何抉择呢？==  

针对上述场景， ShardingSphere 提供了⼀种解决思路。 它提出了连接模式（ConnectionMode）的概念，==将其划分为内存限制模式（MEMORY_STRICTLY）和连接限制模式（CONNECTION_STRICTLY）这两种类型。==  

![image-20220822235834440](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220822235834440.png)

- 内存限制模式

使⽤此模式的前提是， ShardingSphere 对⼀次操作所耗费的数据库连接数量不做限制。  ==如果实际执⾏的 SQL 需要对某数据库实例中的 200 张表做操作，则对每张表创建⼀个新的数据库连接，并通过多线程的⽅式并发处理，以达成执⾏效率最⼤化。== 并且在 SQL 满⾜条件情况下，优先选择流式归并，以防⽌出现内存溢出或避免频繁垃圾回收情况。  

- 连接限制模式

使⽤此模式的前提是， ShardingSphere 严格控制对⼀次操作所耗费的数据库连接数量。  如果实际执⾏的 SQL 需要对某数据库实例中的 200 张表做操作，那么只会创建唯⼀的数据库连接，并对其 200 张表串⾏处理。   如果⼀次操作中的分⽚散落在不同的数据库，仍然采⽤多线程处理对不同库的操作，但==每个库的每次操作仍然只创建⼀个唯⼀的数据库连接。==  这样即可以防⽌对⼀次请求对数据库连接占⽤过多所带来的问题。该模式始终选择内存归并。  

内存限制模式适⽤于 OLAP 操作，可以通过放宽对数据库连接的限制提升系统吞吐量；   连接限制模式适⽤于 OLTP 操作， OLTP 通常带有分⽚键，会路由到单⼀的分⽚，因此严格控制数据库连接，以保证在线系统数据库资源能够被更多的应⽤所使⽤，是明智的选择。  

#### 3.2 自动化执行引擎

ShardingSphere 最初将使⽤何种模式的决定权交由⽤户配置，让开发者依据⾃⼰业务的实际场景需求选择使⽤内存限制模式或连接限制模式。  

这种解决⽅案将两难的选择的决定权交由⽤户，使得⽤户必须要了解这两种模式的利弊，并依据业务场景需求进⾏选择。 这⽆疑增加了⽤户对 ShardingSphere 的学习和使⽤的成本，并⾮最优⽅案。  

这种⼀分为⼆的处理⽅案，将两种模式的切换交由静态的初始化配置，是缺乏灵活应对能⼒的。在实际的使⽤场景中，⾯对不同 SQL 以及占位符参数，每次的路由结果是不同的。 这意味着某些操作可能需要使⽤内存归并，⽽某些操作则可能选择流式归并更优，具体采⽤哪种⽅式不应该由⽤户在 ShardingSphere 启动之前配置好，⽽是应该根据 SQL 和占位符参的场景，来动态的决定连接模式。  

为了降低⽤户的使⽤成本以及连接模式动态化这两个问题， ShardingSphere 提炼出⾃动化执⾏引擎的思路，在其内部消化了连接模式概念。⽤户⽆需了解所谓的内存限制模式和连接限制模式是什么，⽽是交由执⾏引擎根据当前场景⾃动选择最优的执⾏⽅案。    

⾃动化执⾏引擎将连接模式的选择粒度细化⾄每⼀次 SQL 的操作。 针对每次 SQL 请求，⾃动化执⾏引擎都将根据其路由结果，进⾏实时的演算和权衡，并⾃主地采⽤恰当的连接模式执⾏，以达到资源控制和效率的最优平衡。 ==针对⾃动化的执⾏引擎，⽤户只需配置maxConnectionSizePerQuery 即可，该参数表示⼀次查询时每个数据库所允许使⽤的最⼤连接数。==  

执⾏引擎分为准备和执⾏两个阶段。  

#### 3.3 准备阶段

顾名思义，此阶段⽤于准备执⾏的数据。它分为结果集分组和执⾏单元创建两个步骤。  

结果集分组是实现内化连接模式概念的关键。执⾏引擎根据 maxConnectionSizePerQuery配置项，结合当前路由结果，选择恰当的连接模式。 具体步骤如下：  

- 将 SQL 的路由结果按照数据源的名称进⾏分组  
- 通过下图的公式，可以获得每个数据库实例在 maxConnectionSizePerQuery 的允许范围内，每个连接需要执⾏的 SQL 路由结果组，并计算出本次请求的最优连接模式。  

![image-20220823001002560](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220823001002560.png)

在 maxConnectionSizePerQuery 允许的范围内，当⼀个连接需要执⾏的请求数量⼤于 1时，意味着当前的数据库连接⽆法持有相应的数据结果集，则必须采⽤内存归并； 反之，当⼀个连接需要执⾏的请求数量等于 1 时，意味着当前的数据库连接可以持有相应的数据结果集，则可以采⽤流式归并。  

每⼀次的连接模式的选择，是针对每⼀个物理数据库的。也就是说，在同⼀次查询中，如果路由⾄⼀个以上的数据库，每个数据库的连接模式不⼀定⼀样，它们可能是混合存在的形态。  

## 4、实现原理-归并引擎  

将从各个数据节点获取的多数据结果集，组合成为⼀个结果集并正确的返回⾄请求客户端，称为结果归并。 

==ShardingSphere ⽀持的结果归并从功能上分为遍历、排序、分组、分⻚和聚合 5 种类型==，它们是组合⽽⾮互斥的关系。 从结构划分，可分为流式归并、内存归并和装饰者归并。流式归并和内存归并是互斥的，装饰者归并可以在流式归并和内存归并之上做进⼀步的处理。

由于从数据库中返回的结果集是逐条返回的，并不需要将所有的数据⼀次性加载⾄内存中，因此，在进⾏结果归并时，沿⽤数据库返回结果集的⽅式进⾏归并，能够极⼤减少内存的消耗，是归并⽅式的优先选择。  

流式归并是指每⼀次从结果集中获取到的数据，都能够通过逐条获取的⽅式返回正确的单条数据，它与数据库原⽣的返回结果集的⽅式最为契合。遍历、排序以及流式分组都属于流式归并的⼀种。  

内存归并则是需要将结果集的所有数据都遍历并存储在内存中，再通过统⼀的分组、排序以及聚合等计算之后，再将其封装成为逐条访问的数据结果集返回。  

装饰者归并是对所有的结果集归并进⾏统⼀的功能增强，⽬前装饰者归并有分⻚归并和聚合归并这 2 种类型。  

#### 4.1 遍历归并  

它是最为简单的归并⽅式。 只需将多个数据结果集合并为⼀个单向链表即可。在遍历完成链表中当前数据结果集之后，将链表元素后移⼀位，继续遍历下⼀个数据结果集即可。  

#### 4.2 排序归并  

由于在 SQL 中存在 `ORDER BY` 语句，因此每个数据结果集⾃身是有序的，因此只需要将数据结果集当前游标指向的数据值进⾏排序即可。 这相当于对多个有序的数组进⾏排序，归并排序是最适合此场景的排序算法。  

ShardingSphere 在对排序的查询进⾏归并时，将每个结果集的当前数据值进⾏⽐较（通过实现 Java 的 Comparable 接⼝完成），并将其放⼊优先级队列。 每次获取下⼀条数据时，只需将队列顶端结果集的游标下移，并根据新游标重新进⼊优先级排序队列找到⾃⼰的位置即可。

通过⼀个例⼦来说明 ShardingSphere 的排序归并，下图是⼀个通过分数进⾏排序的示例图。 图中展示了 3 张表返回的数据结果集，每个数据结果集已经根据分数排序完毕，但是 3个数据结果集之间是⽆序的。 将 3 个数据结果集的当前游标指向的数据值进⾏排序，并放⼊优先级队列， t_score_0 的第⼀个数据值最⼤， t_score_2 的第⼀个数据值次之， t_score_1的第⼀个数据值最⼩，因此优先级队列根据 t_score_0， t_score_2 和 t_score_1 的⽅式排序队列。    

![image-20220823001502523](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220823001502523.png)

下图则展现了进⾏ next 调⽤的时候，排序归并是如何进⾏的。 通过图中我们可以看到，当进⾏第⼀次 next 调⽤时，排在队列⾸位的 t_score_0 将会被弹出队列，并且将当前游标指向的数据值（也就是 100）返回⾄查询客户端，  并且将游标下移⼀位之后，重新放⼊优先级队列。 ⽽优先级队列也会根据 t_score_0 的当前数据结果集指向游标的数据值（这⾥是 90）进⾏排序，根据当前数值， t_score_0 排列在队列的最后⼀位。 之前队列中排名第⼆的t_score_2 的数据结果集则⾃动排在了队列⾸位。  

在进⾏第⼆次 next 时，只需要将⽬前排列在队列⾸位的 t_score_2 弹出队列，并且将其数据结果集游标指向的值返回⾄客户端，并下移游标，继续加⼊队列排队，以此类推。 当⼀个结果集中已经没有数据了，则⽆需再次加⼊队列。  

![image-20220823001556973](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220823001556973.png)

可以看到，对于每个数据结果集中的数据有序，⽽多数据结果集整体⽆序的情况下，  ShardingSphere ⽆需将所有的数据都加载⾄内存即可排序。 它使⽤的是流式归并的⽅式，每次 next 仅获取唯⼀正确的⼀条数据，极⼤的节省了内存的消耗。  

从另⼀个⻆度来说， ShardingSphere 的排序归并，是在维护数据结果集的纵轴和横轴这两个维度的有序性。 纵轴是指每个数据结果集本身，它是天然有序的，它通过包含 ORDER BY 的SQL 所获取。  横轴是指每个数据结果集当前游标所指向的值，它需要通过优先级队列来维护其正确顺序。 每⼀次数据结果集当前游标的下移，都需要将该数据结果集重新放⼊优先级队列排序，⽽只有排列在队列⾸位的数据结果集才可能发⽣游标下移的操作。  

#### 4.3 分组归并  

分组归并的情况最为复杂，它分为流式分组归并和内存分组归并。 流式分组归并要求 SQL 的排序项与分组项的字段以及排序类型（ASC 或 DESC）必须保持⼀致，否则只能通过内存归并才能保证其数据的正确性。  

举例说明，假设根据科⽬分⽚，表结构中包含考⽣的姓名（为了简单起⻅，不考虑重名的情况）和分数。通过 SQL 获取每位考⽣的总分，可通过如下 SQL：

```sql
SELECT name, SUM(score) FROM t_score GROUP BY name ORDER BY name;
```

  在分组项与排序项完全⼀致的情况下，取得的数据是连续的，分组所需的数据全数存在于各个数据结果集的当前游标所指向的数据值，因此可以采⽤流式归并。如下图所示。  

![image-20220823001727604](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220823001727604.png)

进⾏归并时，逻辑与排序归并类似。 下图展现了进⾏ next 调⽤的时候，流式分组归并是如何进⾏的。  

![image-20220823001742433](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220823001742433.png)

通过图中我们可以看到，当进⾏第⼀次 next 调⽤时，排在队列⾸位的 t_score_java 将会被弹出队列，并且将分组值同为 “Jerry” 的其他结果集中的数据⼀同弹出队列。  在获取了所有的姓名为 “Jerry” 的同学的分数之后，进⾏累加操作，那么，在第⼀次 next 调⽤结束后，取出的结果集是 “Jerry” 的分数总和。与此同时，所有的数据结果集中的游标都将下移⾄数据值“Jerry” 的下⼀个不同的数据值，并且根据数据结果集当前游标指向的值进⾏重排序。 因此，包含名字顺着第⼆位的 “John” 的相关数据结果集则排在的队列的前列。     

流式分组归并与排序归并的区别仅仅在于两点：  

- 它会⼀次性的将多个数据结果集中的分组项相同的数据全数取出。  
- 它需要根据聚合函数的类型进⾏聚合计算。  

对于分组项与排序项不⼀致的情况，由于需要获取分组的相关的数据值并⾮连续的，因此⽆法使⽤流式归并，需要将所有的结果集数据加载⾄内存中进⾏分组和聚合。 例如，若通过以下 SQL 获取每位考⽣的总分并按照分数从⾼⾄低排序：  

```sql
SELECT name, SUM(score) FROM t_score GROUP BY name ORDER BY score DESC;
```

那么各个数据结果集中取出的数据与排序归并那张图的上半部分的表结构的原始数据⼀致，是⽆法进⾏流式归并的。  

当 SQL 中只包含分组语句时，根据不同数据库的实现，其排序的顺序不⼀定与分组顺序⼀致。 但由于排序语句的缺失，则表示此 SQL 并不在意排序顺序。 因此， ShardingSphere 通过 SQL 优化的改写，⾃动增加与分组项⼀致的排序项，使其能够从消耗内存的内存分组归并⽅式转化为流式分组归并⽅案。  

#### 4.4 聚合归并  

⽆论是流式分组归并还是内存分组归并，对聚合函数的处理都是⼀致的。 除了分组的 SQL 之外，不进⾏分组的 SQL 也可以使⽤聚合函数。 因此，聚合归并是在之前介绍的归并类的之上追加的归并能⼒，即装饰者模式。聚合函数可以归类为⽐较、累加和求平均值这 3 种类型。

⽐较类型的聚合函数是指 MAX 和 MIN 。它们需要对每⼀个同组的结果集数据进⾏⽐较，并且直接返回其最⼤或最⼩值即可。    

累加类型的聚合函数是指 SUM 和 COUNT 。它们需要将每⼀个同组的结果集数据进⾏累加。  

求平均值的聚合函数只有 AVG 。它必须通过 SQL 改写的 SUM 和 COUNT 进⾏计算，相关内容已在 SQL 改写的内容中涵盖，不再赘述。  

#### 5.5 分⻚归并  

上⽂所述的所有归并类型都可能进⾏分⻚。 分⻚也是追加在其他归并类型之上的装饰器，ShardingSphere 通过装饰者模式来增加对数据结果集进⾏分⻚的能⼒。 分⻚归并负责将⽆需获取的数据过滤掉。  

ShardingSphere 的分⻚功能⽐较容易让使⽤者误解，⽤户通常认为分⻚归并会占⽤⼤量内存。 在分布式的场景中，将 `LIMIT 10000000, 10 `改写为 `LIMIT 0, 10000010` ，才能保证其数据的正确性。 ⽤户⾮常容易产⽣ ShardingSphere 会将⼤量⽆意义的数据加载⾄内存中，造成内存溢出⻛险的错觉。

其实，通过流式归并的原理可知，会将数据全部加载到内存中的只有内存分组归并这⼀种情况。 ⽽通常来说，进⾏ OLAP 的分组 SQL，不会产⽣⼤量的
结果数据，它更多的⽤于⼤量的计算，以及少量结果产出的场景。 除了内存分组归并这种情况之外，其他情况都通过流式归并获取数据结果集，因此 ShardingSphere 会通过结果集的next ⽅法将⽆需取出的数据全部跳过，并不会将其存⼊内存。  

但同时需要注意的是，由于排序的需要，⼤量的数据仍然需要传输到 ShardingSphere 的内存空间。 因此，采⽤ LIMIT 这种⽅式分⻚，并⾮最佳实践。 由于 LIMIT 并不能通过索引查询数据，因此如果可以保证 ID 的连续性，通过 ID 进⾏分⻚是⽐较好的解决⽅案，例如：    

```sql
SELECT * FROM t_order WHERE id > 100000 AND id <= 100010 ORDER BY id;
```

或通过记录上次查询结果的最后⼀条记录的 ID 进⾏下⼀⻚的查询，例如：  

```sql
SELECT * FROM t_order WHERE id > 10000000 LIMIT 10;
```

归并引擎的整体结构划分如下图。  

![image-20220823002102398](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220823002102398.png)