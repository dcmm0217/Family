# 第2节-ElasticSearch基本概念

## 2.1 Java基本API的调用

见目录下code

## 2.2 ES的核心概念

#### 1、索引（Index）

**一个索引就是一个拥有几分相似特征的文档的集合。**  

比如说，你可以有一个客户数据的索引，另一个产品目录的索引，还有一个订单数据的索引。一个索引由一个名字来标识（必须全是小写字母），并且当我们要对这个索引中的文档进行索引、搜索、更新和删除的时候，都要使用到这个名字。在一个集群中，可以定义任意多的索引。  

**能搜索的数据必须索引，这样的好处是可以提高查询速度，比如：新华字典前面的目录就是索引的意思，目录可以提高查询速度。**  

==Elasticsearch 索引的精髓：一切设计都是为了提高搜索的性能==

#### 2、类型（Type）

在一个索引中，你可以定义一种或多种类型。

一个类型是你的索引的一个逻辑上的==分类/分区==，其语义完全由你来定。

==通常，会为具有一组共同字段的文档定义一个类型。不同的版本，类型发生了不同的变化==  

![image-20220724234141806](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220724234141806.png)

#### 3、字段（Field）

==相对是数据表的字段，对文档数据根据不同属性进行的分类标识。==

#### 4、映射（Mapping）

mapping 是处理数据的方式和规则方面做一些限制，如：某个字段的数据类型、默认值、分析器、是否被索引等等。  

这些都是映射里面可以设置的，其它就是处理 ES 里面数据的一些使用规则设置也叫做映射 

按着最优规则处理数据对性能提高很大，因此才需要建立映射，并且需要思考如何建立映射才能对性能更好。  

#### 5、分片（Shards）

一个索引可以存储超出单个节点硬件限制的大量数据。  

比如，一个具有 10 亿文档数据的索引占据 1TB 的磁盘空间，而任一节点都可能没有这样大的磁盘空间。 或者单个节点处理搜索请求，响应太慢。  

==为了解决这个问题， Elasticsearch 提供了将索引划分成多份的能力，每一份就称之为分片。==  

当你创建一个索引的时候，你可以指定你想要的分片的数量。  每个分片本身也是一个功能完善并且独立的“索引”，这个“索引”可以被放置到集群中的任何节点上  

分片很重要，主要有两方面的原因：  

1）允许你水平分割 / 扩展你的内容容量。  

2）允许你在分片之上进行分布式的、并行的操作，进而提高性能/吞吐量。  

至于一个分片怎样分布，它的文档怎样聚合和搜索请求，是完全由 Elasticsearch 管理的，对于作为用户的你来说，这些都是透明的，无需过分关心。  

![image-20220725234524830](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220725234524830.png)

#### 6、副本（Replicas）

在一个网络 / 云的环境里，失败随时都可能发生，在某个分片/节点不知怎么的就处于离线状态，或者由于任何原因消失了，这种情况下，==有一个故障转移机制是非常有用并且是强烈推荐的。==为此目的， Elasticsearch 允许你创建分片的一份或多份拷贝，这些拷贝叫做复制分片(副本)。  

复制分片之所以重要，有两个主要原因：  

- 在分片/节点失败的情况下，提供了高可用性。  因为这个原因，==注意到复制分片从不与原/主要（original/primary）分片置于同一节点上是非常重要的。==  

- 扩展你的搜索量/吞吐量，因为搜索可以在所有的副本上并行运行。  （默认负载是轮询策略）

总之，每个索引可以被分成多个分片。  一个索引也可以被复制 0 次（意思是没有复制）或多次。

一旦复制了，每个索引就有了主分片（作为复制源的原来的分片）和复制分片（主分片的拷贝）之别。 分片和复制的数量可以在索引创建的时候指定。==在索引创建之后，你可以在任何时候动态地改变复制的数量，但是你事后不能改变分片的数量。==    

默认情况下，Elasticsearch 中的每个索引被分片 1 个主分片和 1 个复制， 这意味着，如果你的集群中至少有两个节点，你的索引将会有 1 个主分片和另外 1 个复制分片（1 个完全拷贝），这样的话每个索引总共就有 2 个分片， 我们需要根据索引需要确定分片个数。  

#### 7、分配（Allocation）

将分片分配给某个节点的过程，包括分配主分片或者副本。==如果是副本，还包含从主分片复制数据的过程==。这个过程是由 master 节点完成的。

## 2.3 ES的系统架构

![image-20220725235126486](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220725235126486.png)

一个运行中的 Elasticsearch 实例称为一个节点，而集群是由一个或者多个拥有相同cluster.name 配置的节点组成，它们共同承担数据和负载的压力。当有节点加入集群中或者从集群中移除节点时，集群将会重新平均分布所有的数据。  

当一个节点被选举成为主节点时， 它将负责管理集群范围内的所有变更，例如增加、删除索引，或者增加、删除节点等。而主节点并不需要涉及到文档级别的变更和搜索等操作，所以当集群只拥有一个主节点的情况下，即使流量的增加它也不会成为瓶颈。任何节点都可以成为主节点。我们的示例集群就只有一个节点，所以它同时也成为了主节点。 

作为用户，我们可以将请求发送到集群中的任何节点 ，包括主节点。  每个节点都知道任意文档所处的位置，并且能够将我们的请求直接转发到存储我们所需文档的节点。  无论我们将请求发送到哪个节点，它都能负责从各个包含我们所需文档的节点收集回数据，并将最终结果返回給客户端。 Elasticsearch 对这一切的管理都是透明的 。

## 2.4 分布式集群

#### 1、单节点集群

我们在包含一个空节点的集群内创建名为 users 的索引，为了演示目的，我们将分配 3个主分片和一份副本（每个主分片拥有一个副本分片）  

![image-20220726232929802](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220726232929802.png)

我们的集群现在是拥有一个索引的单节点集群。所有 3 个主分片都被分配在 node-1 。  

![image-20220726232944355](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220726232944355.png)

#### 2、故障转移

当集群中只有一个节点在运行时，意味着会有一个单点故障问题——没有冗余。幸运的是，我们只需再启动一个节点即可防止数据丢失。    

当你在同一台机器上启动了第二个节点时，只要它和第一个节点有同样的 cluster.name 配置，它就会自动发现集群并加入到其中。但是在不同机器上启动节点的时候，为了加入到同一集群，你需要配置一个可连接到的单播主机列表。之所以配置为使用单播发现，以防止节点无意中加入集群。只有在同一台机器上运行的节点才会自动组成集群。  

如果启动了第二个节点，我们的集群将会拥有两个节点的集群 : 所有主分片和副本分片都已被分配  

![image-20220726233214991](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220726233214991.png)

#### 3、水平扩容

怎样为我们的正在增长中的应用程序按需扩容呢？==当启动了第三个节点，我们的集群将会拥有三个节点的集群 : 为了分散负载而对分片进行重新分配==  

![image-20220726233301196](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220726233301196.png)

**但是如果我们想要扩容超过 6 个节点怎么办呢？**  

主分片的数目在索引创建时就已经确定了下来。  实际上，这个数目定义了这个索引能够存储 的最大数据量（实际大小取决于你的数据、硬件和使用场景。）  

==但是，读操作——搜索和返回数据——可以同时被主分片 或 副本分片所处理，所以当你拥有越多的副本分片时，也将拥有越高的吞吐量。==  

在运行中的集群上是可以动态调整副本分片数目的，我们可以按需伸缩集群。让我们把副本数从默认的 1 增加到 2  

```
{
	"number_of_replicas" : 2
}
```

![image-20220726233539071](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220726233539071.png)

当然，如果只是在相同节点数目的集群上增加更多的副本分片并不能提高性能，因为每个分片从节点上获得的资源会变少。 你需要增加更多的硬件资源来提升吞吐量 。

但是更多的副本分片数提高了数据冗余量：按照上面的节点配置，我们可以在失去 2 个节点的情况下不丢失任何数据  

#### 4、应对故障

我们关闭第一个节点，这时集群的状态为:关闭了一个节点后的集群。  

![image-20220726233623786](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220726233623786.png)

我们关闭的节点是一个主节点。而集群必须拥有一个主节点来保证正常工作，所以发生的第一件事情就是选举一个新的主节点： Node 2 。  

在我们关闭 Node 1 的同时也失去了主分片 1 和 2 ，并且在缺失主分片的时候索引也不能正常工作。 如果此时来检查集群的状 况，我们看到的状态将会为 red ：不是所有主分片都在正常工作。  

![image-20220726233650229](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220726233650229.png)

幸运的是，在其它节点上存在着这两个主分片的完整副本，  所以新的主节点立即将这些分片在 Node 2 和 Node 3 上对应的副本分片提升为主分片，此时集群的状态将会为 yellow。这个提升主分片的过程是瞬间发生的，如同按下一个开关一般。    

**为什么我们集群状态是 yellow 而不是 green 呢？**  

虽然我们拥有所有的三个主分片，但是同时设置了每个主分片需要对应 2 份副本分片，而此时只存在一份副本分片。   所以集群不能为 green 的状态，不过我们不必过于担心：如果我们同样关闭了 Node 2 ，我们的程序 依然 可以保持在不丢任何数据的情况下运行，因为Node 3 为每一个分片都保留着一份副本。  

如果我们重新启动 Node 1 ，集群可以将缺失的副本分片再次进行分配，那么集群的状态也将恢复成之前的状态。   

如果 Node 1 依然拥有着之前的分片，它将尝试去重用它们，同时仅从主分片复制发生了修改的数据文件。和之前的集群相比，只是 Master 节点切换了。  

![image-20220726233935548](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220726233935548.png)

#### 5、路由计算

当索引一个文档的时候，文档会被存储到一个主分片中。  

Elasticsearch 如何知道一个文档应该存放到哪个分片中呢？当我们创建文档时，它如何决定这个文档应当被存储在分片1 还是分片 2 中呢？  

首先这肯定不会是随机的，否则将来要获取文档的时候我们就不知道从何处寻找了。实际上，这个过程是根据下面这个公式决定的：  

![image-20220726234005972](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220726234005972.png)

==routing 是一个可变值，默认是文档的 _id ，也可以设置成一个自定义的值。 routing 通过hash 函数生成一个数字，然后这个数字再除以 number_of_primary_shards （主分片的数量）后得到余数 。  这个分布在 0 到 number_of_primary_shards-1 之间的余数，就是我们所寻求
的文档所在分片的位置。==  

![image-20220726234646584](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220726234646584.png)

这就解释了为什么我们要在创建索引的时候就确定好主分片的数量 并且永远不会改变这个数量：因为如果数量变化了，那么所有之前路由的值都会无效，文档也再也找不到了。  

所有的文档 API（ get 、 index 、 delete 、 bulk 、 update 以及 mget ）都接受一个叫做 routing 的路由参数 ，通过这个参数我们可以自定义文档到分片的映射。一个自定义的路由参数可以用来确保所有相关的文档——例如所有属于同一个用户的文档——都被存储到同一个分片中。   

#### 6、分片控制

我们假设有一个集群由三个节点组成。 它包含一个叫 emps 的索引，有两个主分片，每个主分片有两个副本分片。相同分片的副本不会放在同一节点。  

![image-20220726234205021](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220726234205021.png)

==我们可以发送请求到集群中的任一节点。 每个节点都有能力处理任意请求。==  每个节点都知道集群中任一文档位置，所以可以直接将请求转发到需要的节点上。 在下面的例子中，将所有的请求发送到 Node 1，我们将其称为 ==协调节点==(coordinating node)  

![image-20220726234706422](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220726234706422.png)

**当发送请求的时候， 为了扩展负载，更好的做法是轮询集群中所有的节点。**  



## 2.5 数据流程

#### 1、写流程

新建、索引和删除 请求都是 写 操作， 必须在主分片上面完成之后才能被复制到相关的副本分片  

![image-20220726234516972](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220726234516972.png)

**新建，索引和删除文档所需要的步骤顺序：**  

![image-20220726234528333](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220726234528333.png)

![image-20220726234723003](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220726234723003.png)

在客户端收到成功响应时，文档变更已经在主分片和所有副本分片执行完成，变更是安全的。  

有一些可选的请求参数允许您影响这个过程，可能以数据安全为代价提升性能。这些选少使用，因为 Elasticsearch 已经很快，但是为了完整起见， 请参考下面表格：  

![image-20220726234600441](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220726234600441.png)

==新索引默认有 1 个副本分片，这意味着为满足规定数量应该需要两个活动的分片副本。 但是，这些默认的设置会阻止我们在单一节点上做任何事情。为了避免这个问题，要求只有当 number_of_replicas 大于 1 的时候，规定数量才会执行。==  

#### 2、读流程

我们可以从主分片或者从其它任意副本分片检索文档 

 ![image-20220726234752272](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220726234752272.png)

![image-20220726234801326](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220726234801326.png)

![image-20220726234845335](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220726234845335.png)

#### 3、更新流程  

部分更新一个文档结合了先前说明的读取和写入流程：  

![image-20220726234914538](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220726234914538.png)

当主分片把更改转发到副本分片时， 它不会转发更新请求。  相反，它转发完整文档的新版本。  

请记住，这些更改将会异步转发到副本分片，并且不能保证它们以发送它们相同的顺序到达。如果 Elasticsearch 仅转发更改请求，则可能以错误的顺序应用更改，导致得到损坏的文档。  

#### 4、文档操作流程  

mget 和 bulk API 的模式类似于单文档模式。区别在于协调节点知道每个文档存在于哪个分片中。它将整个多文档请求分解成 每个分片 的多文档请求，并且将这些请求并行转发到每个参与节点。  

协调节点一旦收到来自每个节点的应答，就将每个节点的响应收集整理成单个响应，返回给客户端  

![image-20220726235028563](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220726235028563.png)

用单个 mget 请求取回多个文档所需的步骤顺序:  

1、客户端向 Node 1 发送 mget 请求。  

2、Node 1 为每个分片构建多文档获取请求，然后并行转发这些请求到托管在每个所需的主分片或者副本分片的节点上。  一旦收到所有答复， Node 1 构建响应并将其返回给客户端。  

可以对 docs 数组中每个文档设置 routing 参数。  

bulk API， 允许在单个批量请求中执行多个创建、索引、删除和更新请求。  

![image-20220726235116587](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220726235116587.png)

## 2.6 分片原理

分片是 Elasticsearch 最小的工作单元。但是究竟什么是一个分片，它是如何工作的？  

==传统的数据库每个字段存储单个值，但这对全文检索并不够。 文本字段中的每个单词需要被搜索，对数据库意味着需要单个字段有索引多值的能力。最好的支持是一个字段多个值需求的数据结构是倒排索引。==  

#### 1、倒排索引

==Elasticsearch 使用一种称为倒排索引的结构，它适用于快速的全文搜索。==  

见其名， 知其意，有倒排索引，肯定会对应有正向索引。正向索引（forward index），反向索引（inverted index）更熟悉的名字是倒排索引。  

所谓的正向索引，就是搜索引擎会将待搜索的文件都对应一个文件 ID，搜索时将这个ID 和搜索关键字进行对应，形成 K-V 对，然后对关键字进行统计计数  

![image-20220726235349167](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220726235349167.png)

但是互联网上收录在搜索引擎中的文档的数目是个天文数字，这样的索引结构根本无法满足实时返回排名结果的要求。   

所以，搜索引擎会将正向索引重新构建为倒排索引，即把文件ID对应到关键词的映射转换为关键词到文件ID的映射，每个关键词都对应着一系列的文件，这些文件中都出现这个关键词。  

![image-20220726235423681](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220726235423681.png)

一个倒排索引由文档中所有不重复词的列表构成，对于其中每个词，有一个包含它的文档列表。例如， 假设我们有两个文档，每个文档的 content 域包含如下内容：  

- The quick brown fox jumped over the lazy dog  
- Quick brown foxes leap over lazy dogs in summer  

==为了创建倒排索引，我们首先将每个文档的 content 域拆分成单独的 `词`（我们称它为 `词条`或 tokens ）==，创建一个包含所有不重复词条的排序列表，然后列出每个词条出现在哪个文档。结果如下所示：  

![image-20220726235558262](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220726235558262.png)

现在，如果我们想搜索 `quick` `brown` ，我们只需要查找包含每个词条的文档：  

![image-20220726235622939](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220726235622939.png)

两个文档都匹配，但是第一个文档比第二个匹配度更高。如果我们使用仅计算匹配词条数量的简单相似性算法，那么我们可以说，对于我们查询的相关性来讲，第一个文档比第二个文档更佳。

但是，我们目前的倒排索引有一些问题：

- `Quick`和`quick`以独立的词条出现，然而用户可能认为它们是相同的词。

- `fox`和`foxes`非常相似，就像`dog`和`dogs`；他们有相同的词根。
- `jumped`和`leap`，尽管没有相同的词根，但他们的意思很相近。他们是同义词。

使用前面的索引搜索`+Quick` `+fox`不会得到任何匹配文档。(记住，＋前缀表明这个词必须存在）。

只有同时出现`Quick`和`fox` 的文档才满足这个查询条件，但是第一个文档包含`quick` `fox` ，第二个文档包含`Quick` `foxes` 。

我们的用户可以合理的期望两个文档与查询匹配。我们可以做的更好。

如果我们将词条规范为标准模式，那么我们可以找到与用户搜索的词条不完全一致，但具有足够相关性的文档。

例如：

- `Quick`可以小写化为`quick`。
- `foxes`可以词干提取变为词根的格式为`fox`。类似的，`dogs`可以为提取为`dog`。
- `jumped`和`leap`是同义词，可以索引为相同的单词`jump` 。

现在索引看上去像这样：

![image-20220726235730464](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220726235730464.png)

这还远远不够。我们搜索`+Quick` `+fox` 仍然会失败，因为在我们的索引中，已经没有`Quick`了。但是，如果我们对搜索的字符串使用与content域相同的标准化规则，会变成查询`+quick` `+fox`，这样两个文档都会匹配！==分词和标准化的过程称为**分析**==，这非常重要。==你只能搜索在索引中出现的词条，所以索引文本和查询字符串必须标准化为相同的格式。==

#### 2、文档搜索

不可改变的倒排索引

早期的全文检索会为整个文档集合建立一个很大的倒排索引并将其写入到磁盘。 一旦新的索引就绪，旧的就会被其替换，这样最近的变化便可以被检索到。

倒排索引被写入磁盘后是不可改变的：它永远不会修改。

- 不需要锁。如果你从来不更新索引，你就不需要担心多进程同时修改数据的问题。

- 一旦索引被读入内核的文件系统缓存，便会留在哪里，由于其不变性。只要文件系统缓存中还有足够的空间，那么大部分读请求会直接请求内存，而不会命中磁盘。这提供了很大的性能提升。

- 其它缓存(像filter缓存)，在索引的生命周期内始终有效。它们不需要在每次数据改变时被重建，因为数据不会变化。

- 写入单个大的倒排索引允许数据被压缩，减少磁盘IO和需要被缓存到内存的索引的使用量。

当然，一个不变的索引也有不好的地方。主要事实是它是不可变的! 你不能修改它。如果你需要让一个新的文档可被搜索，你需要重建整个索引。这要么对一个索引所能包含的数据量造成了很大的限制，要么对索引可被更新的频率造成了很大的限制。

#### 3、动态更新索引

如何在保留不变性的前提下实现倒排索引的更新？

答案是：用更多的索引。通过增加新的补充索引来反映新近的修改，而不是直接重写整个倒排索引。每一个倒排索引都会被轮流查询到,从最早的开始查询完后再对结果进行合并。

Elasticsearch基于Lucene，这个java库引入了**按段搜索**的概念。每一段本身都是一个倒排索引，但索引在 Lucene 中除表示所有段的集合外，还增加了提交点的概念—一个列出了所有已知段的文件。

![image-20220803223317538](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220803223317538.png)

按段搜索会以如下流程执行：

一、新文档被收集到内存索引缓存。

![image-20220803223328928](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220803223328928.png)

二、不时地, 缓存被提交。

1. 一个新的段，一个追加的倒排索引，被写入磁盘。
2. 一个新的包含新段名字的提交点被写入磁盘。
3. 磁盘进行同步，所有在文件系统缓存中等待的写入都刷新到磁盘，以确保它们被写入物理文件

三、新的段被开启，让它包含的文档可见以被搜索。

四、内存缓存被清空，等待接收新的文档。

![image-20220803223416992](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220803223416992.png)

当一个查询被触发，所有已知的段按顺序被查询。词项统计会对所有段的结果进行聚合，以保证每个词和每个文档的关联都被准确计算。这种方式可以用相对较低的成本将新文档添加到索引。

段是不可改变的，所以既不能从把文档从旧的段中移除，也不能修改旧的段来进行反映文档的更新。取而代之的是，每个提交点会包含一个.del 文件，文件中会列出这些被删除文档的段信息。

当一个**文档被“删除”**时，它实际上只是在 .del 文件中被标记删除。一个被标记删除的文档仍然可以被查询匹配到，但它会在最终结果被返回前从结果集中移除。

**文档更新**也是类似的操作方式:当一个文档被更新时，旧版本文档被标记删除，文档的新版本被索引到一个新的段中。可能两个版本的文档都会被一个查询匹配到，但被删除的那个旧版本文档在结果集返回前就已经被移除。

#### 4、文档刷新 & 文档刷写 & 文档合并

![image-20220803223709311](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220803223709311.png)

#### 5、近实时搜索

随着按段（per-segment）搜索的发展，一个新的文档从索引到可被搜索的延迟显著降低了。新文档在几分钟之内即可被检索，但这样还是不够快。磁盘在这里成为了瓶颈。**提交（Commiting）一个新的段到磁盘需要一个fsync来确保段被物理性地写入磁盘**，这样在断电的时候就不会丢失数据。但是fsync操作代价很大；如果每次索引一个文档都去执行一次的话会造成很大的性能问题。

我们需要的是一个更轻量的方式来使一个文档可被搜索，这意味着fsync要从整个过程中被移除。在Elasticsearch和磁盘之间是**文件系统缓存**。像之前描述的一样，在内存索引缓冲区中的文档会被写入到一个新的段中。但是这里新段会被先写入到文件系统缓存—这一步代价会比较低，稍后再被刷新到磁盘—这一步代价比较高。不过只要文件已经在缓存中，就可以像其它文件一样被打开和读取了。

![image-20220803223805610](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220803223805610.png)

Lucene允许新段被写入和打开，使其包含的文档在未进行一次完整提交时便对搜索可见。这种方式比进行一次提交代价要小得多，并且在不影响性能的前提下可以被频繁地执行。

![image-20220803223833490](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220803223833490.png)

在 Elasticsearch 中，写入和打开一个新段的轻量的过程叫做refresh。默认情况下每个分片会每秒自动刷新一次。这就是为什么我们说 Elasticsearch是近实时搜索：文档的变化并不是立即对搜索可见，但会在一秒之内变为可见。

这些行为可能会对新用户造成困惑：他们索引了一个文档然后尝试搜索它，但却没有搜到。这个问题的解决办法是用refresh API执行一次手动刷新：/usersl_refresh

尽管刷新是比提交轻量很多的操作，它还是会有性能开销。当写测试的时候，手动刷新很有用，但是不要在生产环境下每次索引一个文档都去手动刷新。相反，你的应用需要意识到Elasticsearch 的近实时的性质，并接受它的不足。

并不是所有的情况都需要每秒刷新。可能你正在使用Elasticsearch索引大量的日志文件，你可能想优化索引速度而不是近实时搜索，可以通过设置refresh_interval ，降低每个索引的刷新频率

```json
{
    "settings": {
    	"refresh_interval": "30s"
    }
}

```

refresh_interval可以在既存索引上进行动态更新。在生产环境中，当你正在建立一个大的新索引时，可以先关闭自动刷新，待开始使用该索引时，再把它们调回来。

```json
# 关闭自动刷新
PUT /users/_settings
{ "refresh_interval": -1 }

# 每一秒刷新
PUT /users/_settings
{ "refresh_interval": "1s" }
```

持久化变更

如果没有用fsync把数据从文件系统缓存刷（flush）到硬盘，我们不能保证数据在断电甚至是程序正常退出之后依然存在。为了保证Elasticsearch 的可靠性，需要确保数据变化被持久化到磁盘。在动态更新索引，我们说一次完整的提交会将段刷到磁盘，并写入一个包含所有段列表的提交点。Elasticsearch 在启动或重新打开一个索引的过程中使用这个提交点来判断哪些段隶属于当前分片。

即使通过每秒刷新(refresh）实现了近实时搜索，我们仍然需要经常进行完整提交来确保能从失败中恢复。但在两次提交之间发生变化的文档怎么办?我们也不希望丢失掉这些数据。==Elasticsearch 增加了一个translog ，或者叫事务日志，在每一次对Elasticsearch进行操作时均进行了日志记录==。

整个流程如下:

一、一个文档被索引之后，就会被添加到内存缓冲区，并且追加到了 translog

![image-20220803224129748](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220803224129748.png)

二、刷新（refresh）使分片每秒被刷新（refresh）一次：

- 这些在内存缓冲区的文档被写入到一个新的段中，且没有进行fsync操作。
- 这个段被打开，使其可被搜索。
- 内存缓冲区被清空。

![image-20220803224145112](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220803224145112.png)

三、这个进程继续工作，更多的文档被添加到内存缓冲区和追加到事务日志。

![image-20220803224153416](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220803224153416.png)

四、每隔一段时间—例如translog变得越来越大，索引被刷新（flush）；一个新的translog被创建，并且一个全量提交被执行。

- 所有在内存缓冲区的文档都被写入一个新的段。
- 缓冲区被清空。
- 一个提交点被写入硬盘。
- 文件系统缓存通过fsync被刷新（flush） 。
- 老的translog被删除

translog 提供所有还没有被刷到磁盘的操作的一个持久化纪录。当Elasticsearch启动的时候，它会从磁盘中使用最后一个提交点去恢复己知的段，并且会重放translog 中所有在最后一次提交后发生的变更操作。

translog 也被用来提供实时CRUD。当你试着通过ID查询、更新、删除一个文档，它会在尝试从相应的段中检索之前，首先检查 translog任何最近的变更。这意味着它总是能够实时地获取到文档的最新版本。

![image-20220803224215429](https://mygiteepic.oss-cn-shenzhen.aliyuncs.com/imgimage-20220803224215429.png)

执行一个提交并且截断translog 的行为在 Elasticsearch被称作一次flush。分片每30分钟被自动刷新（flush)，或者在 translog 太大的时候也会刷新。

你很少需要自己手动执行flush操作，通常情况下，自动刷新就足够了。这就是说，在重启节点或关闭索引之前执行 flush有益于你的索引。当Elasticsearch尝试恢复或重新打开一个索引，它需要重放translog中所有的操作，所以如果日志越短，恢复越快。

translog 的目的是保证操作不会丢失，在文件被fsync到磁盘前，被写入的文件在重启之后就会丢失。默认translog是每5秒被fsync刷新到硬盘，或者在每次写请求完成之后执行（e.g. index, delete, update, bulk）。这个过程在主分片和复制分片都会发生。最终，基本上，这意味着在整个请求被fsync到主分片和复制分片的translog之前，你的客户端不会得到一个200 OK响应。

在每次请求后都执行一个fsync会带来一些性能损失，尽管实践表明这种损失相对较小（特别是 bulk 导入，它在一次请求中平摊了大量文档的开销）。

但是对于一些大容量的偶尔丢失几秒数据问题也并不严重的集群，使用异步的 fsync还是比较有益的。比如，写入的数据被缓存到内存中，再每5秒执行一次 fsync 。如果你决定使用异步translog 的话，你需要保证在发生 crash 时，丢失掉 sync_interval时间段的数据也无所谓。请在决定前知晓这个特性。如果你不确定这个行为的后果，最好是使用默认的参数{“index.translog.durability”: “request”}来避免数据丢失。
