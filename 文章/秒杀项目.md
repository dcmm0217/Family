# 秒杀项目



## 1、分布式会话是怎么实现的，为什么要用分布式会话？

#### 1、为什么？

因为我们项目使用了2台应用服务器做了负载均衡和反向代理。如果还是单机版Session的情况，会出现

**在A1系统登录后创建并保存Session，再次发起请求，请求被转发到A2系统上显示未登录的情况**

**所以我们需要把生产的SessionId存到Redis中**

#### 2、实现步骤：

首先我们引入两个Jar包

```xml
<!--redis-->
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-data-redis</artifactId>
    <version>2.3.1.RELEASE</version>
</dependency>
<!--将session 放入redis-->
<dependency>
    <groupId>org.springframework.session</groupId>
    <artifactId>spring-session-data-redis</artifactId>
    <version>2.0.5.RELEASE</version>
</dependency>
```

并且新建一个`RedisConfig`类，暂时不进行任何操作只添加两个注解

```java
@Component
@EnableRedisHttpSession(maxInactiveIntervalInSeconds = 3600)
```

并在properties中添加redis相关配置

```properties
# redis配置
spring.redis.host=（对应服务器主机ip）
spring.redis.port=6379
spring.redis.database=10

# 设置jedis 连接池
spring.redis.jedis.pool.max-active=50
spring.redis.jedis.pool.min-idle=20
```

由于登录时我们将`UserModel`存在session中，现在存储在`redis`中，我们要给`UserModel`**配置序列化操作**。

```
为什么存储到Redis要将实体类进行序列化？
1、任何存储都需要序列化。
2、只不过常规你在用DB一类存储的时候，这个事情DB帮你在内部搞定了（直接把SQL带有类型的数据转换成内部序列化的格式，存储；读取时再解析出来）。
3、redis又不是java专用的，它不支持java特有的数据类型。Redis并不会帮你做这个事情。当你用Redis的key和value时，value对于redis来讲就是个byte array。
```

**登录时，我们生产Token，将其代表`sessionId`与`UserModel`以键值对的形式存入`Redis`中**

```java
String uuidToken = UUID.randomUUID().toString().replaceAll("-","");
// 建立token和用户登录态之间的联系
redisTemplate.opsForValue().set(uuidToken,userModel,1, TimeUnit.HOURS);

// 返回给前端
return CommonReturnType.create(uuidToken);
```

```javascript
// 如果登录成功，则将后端返回的token存放到localStorage里面。
if (data.status == "success") {
    alter("登录成功");
    var token = data.data;
    window.localStorage["token"] = token;
    window.location.href = "listitem.html";
}
```

前端要下单时

```javascript
$("#createorder").on("click", function () {
    var token = window.localStorage["token"];
    if (token == null) {
        alert("没有登录不能下单");
        window.location.href = "login.html";
        return false;
    }
    $("#verifyDiv img").attr("src","http://" + g_host + "/order/generateVerifyCode?token="+token);
    $("#verifyDiv").show();
});
```

后端下单校验用户是否登录

```java
String token = request.getParameterMap().get("token")[0];

if (StringUtils.isEmpty(token)) {
    throw new BusinessException(EmBusinessError.USER_NOT_LOGIN, "用户还未登录,不能下单");
}
//从redis中拿到对应uuid的userModel
UserModel userModel = (UserModel) redisTemplate.opsForValue().get(token);
if (userModel == null) {
    throw new BusinessException(EmBusinessError.USER_NOT_LOGIN, "用户还未登录,不能下单");
}
```

分布式会话，有两种常见的实现方式：

1. 第一种是通过Spring提供的API，将Tomcat的`SessionId`和`UserModel`存到Redis服务器上。
2. 第二种是通过UUID生成登录`token`，将`token`和`UserModel`存到Redis服务器上。



## 2、看你项目上说用到了多级缓存？是怎么用的？为什么要用呢?

首先要明白使用缓存的目的，主要是**提高查询效率**。减少数据库的压力，提高系统的QPS

```
1、Redis缓存
2、热点内存本地缓存（JVM）
3、nginx proxy cache 缓存
4、nginx lua 缓存

```

#### 1、Redis缓存

- 单机版
- sentinal哨兵模式
- 集群cluster模式

我们采用单机版对查询进行缓存

item商品信息，会查询3张表，首先是item**基础信息表**，然后是**库存表**，再者是**promo活动表**（该商品是否参与秒杀活动），故很消耗Mysql的性能，我们采用缓存的方式如果其id相同，则返回相同的Model即可。

**我们采用item_id，表示Item商品+商品id 代表其key；**

Value即是我们的UserModel对象。

**当我们访问商品时，我们先从redis中获取，如果redis中没有，则访问数据库获取，并且写回到redis；**

```java
// ItemController代码
// 根据redis 获取商品 Model
ItemModel itemModel = (ItemModel) redisTemplate.opsForValue().get("item_" + id);
// 若不存在
if(itemModel == null){
    itemModel=itemService.getItemById(id);
    // 将其放入Redis
    redisTemplate.opsForValue().set("item_" + id,itemModel);
    redisTemplate.expire("ietm_"+id,10, TimeUnit.MINUTES);
}
```

然后此时我们查看redis中的数据时是乱码的形式，原因为我们没有配置其序列化格式，其采用自己的一种编码方式

```java
public class RedisAutoConfiguration {
    @Bean
    @ConditionalOnMissingBean(
        name = {"redisTemplate"}// 此注解代表 当我们spring容器中没有redistemplate Bean时，其自动给我们配置此编码格式的Bean
    )
    public RedisTemplate<Object, Object> redisTemplate(RedisConnectionFactory redisConnectionFactory) throws UnknownHostException {
        RedisTemplate<Object, Object> template = new RedisTemplate();
        template.setConnectionFactory(redisConnectionFactory);
        return template;
}
```

此时我们自己配置一个Bean并且解决Reids序列化的问题

```java
@Bean
public RedisTemplate redisTemplate(RedisConnectionFactory redisConnectionFactory){
    RedisTemplate redisTemplate = new RedisTemplate();
    redisTemplate.setConnectionFactory(redisConnectionFactory);

    //首先解决key的序列化格式
    StringRedisSerializer stringRedisSerializer = new StringRedisSerializer();
    redisTemplate.setKeySerializer(stringRedisSerializer);

    //解决value的序列化格式
    Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class);

    //解决日期的序列化格式
    ObjectMapper objectMapper = new ObjectMapper();
    SimpleModule simpleModule = new SimpleModule();
    simpleModule.addSerializer(DateTime.class, new JodaDateTimeJSONSerializer());
    simpleModule.addDeserializer(DateTime.class, new JodaDateTimeDeserializer());

    objectMapper.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);
    objectMapper.registerModule(simpleModule);

    jackson2JsonRedisSerializer.setObjectMapper(objectMapper);
    redisTemplate.setValueSerializer(jackson2JsonRedisSerializer);
    return redisTemplate;
}

// 对于日期而言，序列化后是一个很长的毫秒数。我们希望是yyyy-MM-dd HH:mm:ss的格式，还需要进一步处理。新建serializer包，里面新建两个类。
public class JodaDateTimeJSONSerializer extends JsonSerializer<DateTime> {
    @Override
    public void serialize(DateTime dateTime, JsonGenerator jsonGenerator, SerializerProvider serializerProvider) throws IOException {
        jsonGenerator.writeString(dateTime.toString("yyyy-MM-dd HH:mm:ss"));
    }
}
public class JodaDateTimeDeserializer extends JsonDeserializer<DateTime> {
    @Override
    public DateTime deserialize(JsonParser jsonParser, DeserializationContext deserializationContext) throws IOException, JsonProcessingException {
        String dateString = jsonParser.readValueAs(String.class);
        DateTimeFormatter formatter=DateTimeFormat.forPattern("yyyy-MM-dd HH:mm:ss");
        return DateTime.parse(dateString,formatter);
    }
}
```

#### 2、使用本地缓存优化

虽然Redis很好，但是还是涉及网络的IO，没有本地缓存快，我们在Redis之前添加一层**本地热点**，所谓本地，就是利用本地 JVM的内存，所谓热点，由于 JVM 内存有限，仅存放多次查询的数据（一般是一秒内上 千 甚至上万的访问）。

每个本地缓存也就是存储在各自服务器的，所以我们对脏数据也不是特别敏感，但是一定要有过期时间，并且要设置的比较短。

这里本地缓存我们可以使用`HashMap`,但是其不能支持并发修改，故我们可以选取`ConcurrentHashMap`但是无法高效处理**过期时限**、没有**淘汰机制**等问题，所以这里使用了`Google`的`Guava Cache`方案。**本质上也是一种可并发的hashmap**

```xml
// 配置Guava依赖
<dependency>
    <groupId>com.google.guava</groupId>
    <artifactId>guava</artifactId>
    <version>19.0</version>
</dependency>
```

封装本地缓存的Service接口

```java
//封装本地缓存操作类
public interface CacheService {
    //存方法
    void setCommonCache(String key,Object value);

    //取方法
    Object getFromCommonCache(String key);
}
```

其实现类

```java
@Service
public class CacheServiceImpl implements CacheService {

    private Cache<String,Object> commonCache = null;

    @PostConstruct
    //springbean会在对应bean加载的时候，优先执行对应的init方法
    public void init(){
        commonCache = CacheBuilder.newBuilder()
                //设置缓存容器的初始容量为10
                .initialCapacity(10)
                //设置缓存中最大的可以存放的key，超过100个会按照lru的策略移除缓存项
                .maximumSize(100)
                //设置写缓存后多少秒过期
                .expireAfterWrite(60, TimeUnit.SECONDS).build();
    }

    @Override
    public void setCommonCache(String key, Object value) {
        commonCache.put(key,value);
    }

    @Override
    public Object getFromCommonCache(String key) {
        return commonCache.getIfPresent(key);
    }
}
```

**在获取商品id详情时，先走本地缓存 --- Redis缓存 -- mysql服务器**

```java
//商品信息浏览
@GetMapping(value = "/get")
@ResponseBody
public CommonReturnType getItem(@RequestParam("id")Integer id){
    //多级缓存 优化访问策略   1、本地缓存  2、redis缓存 3、数据库
    ItemModel itemById = null;
    //先去本地缓存
    itemById = (ItemModel) cacheService.getFromCommonCache("item_"+id);
    if (itemById==null){
        //根据商品的id到redis内获取对应的UserModel
        itemById = (ItemModel) redisTemplate.opsForValue().get("item_" + id);
        //若redis内不存在对应的itemModel，则访问下游的service
        if (itemById==null){
            itemById = itemService.getItemById(id);
            //设置itemModel到redis内
            redisTemplate.opsForValue().set("item_"+id,itemById);
            //缓存一定要记得设置过期时间,不仅仅是为了redis的一个容量性能考虑，更为了业务的能力，
            //当我们的数据发生改变，就需要一个清理缓存的机制
            redisTemplate.expire("item_"+id,10, TimeUnit.MINUTES);
        }
        //设置本地缓存
        cacheService.setCommonCache("item_"+id,itemById);
    }
    ItemVO itemVO = convertVOFromModel(itemById);
    return CommonReturnType.create(itemVO);
}
```

至此**tps**能最高到达**4000**，并且保持在**50ms**以内，因为大部分重复的访问全部走向了**本地缓存**，对服务器没有一点压力

**本地缓存的缺点：**

1、更新特别麻烦，容易产生脏缓存

2、受到 JVM 容量限制

#### 3、Nginx Proxy Cache缓存

**启用nginx缓存的条件：**

- nginx可以用作反向代理
- 依靠文件系统存索引级的文件(将请求存成本地文件，在本地磁盘中)
- 依靠内存缓存文件地址（接下来有点绕：内存缓存文件的内容value是以文件形式存放在磁盘中，但是缓存的key以缓存的方式在内存中，缓存key在内存的内容就是 —内存缓存文件的地址）也就是说nginx proxy cahce 寻址的key在内存当中，value在磁盘中，key内存中存储的是value的地址
  

通过**Redis缓存**减少了**MySQL的重复查询**，通过**本地缓存**，减少了Redis的**网络I/O**，大大的提高了效率，但是客户端请求Nginx服务器也有分发过程，需要去请求后面的两台应用服务器，有一定网络I/O，我们可以直接把**热点数据**存放到**Nginx服务器**上。

通过`Nginx Proxy Cache`作为文件存放在指定目录下。

```shell
# 申明一个cache缓存节点 evels 表示以二级目录存放
    proxy_cache_path /usr/local/openresty/nginx/tmp_cache levels=1:2 keys_zone=tmp_cache:100m inactive=7d max_size=10g;
...
server{
    location / {
        #proxy_cache 目录
        proxy_cache tmp_cache;
        proxy_cache_key $uri;
        #只有后端返回以下状态码才缓存
        proxy_cache_valid 200 206 304 302 7d;
    }
}
```

sbin/nginx -s reload重启服务器

这样在tmp_cache/下生成了对应的文件为JSON格式。

但是不好用，它是放在本地磁盘上的，有磁盘I/O，而且一般企业级都是用到的NAS。 一般很少使用。

#### 4、nginx lua脚本

协程机制：

- 依附于线程的内存模型，切换开销小
- 遇阻塞及归还执行权，代码同步
- 无需加锁

后2种方式属于服务器的优化了。

## 3、看你项目里面使用了CDN？怎么用的？全页面静态化是怎么做的？

#### 1、什么是CDN?

CDN可以理解为一个无限大的内容磁盘缓存，本身没有文件存储。当用户访问getItem的一个静态资源文件的时候，会根据路由规则查看本地是否有这样的文件，如果有，直接返回，没有就**回源**到**源站**，回源到下面的OSS中获取静态资源文件。

CDN一边返回对应的文件，一边将文件按照http指示的生命周期缓存起来，以便下次用户访问时，直接返回。

![image-20211116212458789](https://gitee.com/huangwei0123/image/raw/master/img/image-20211116212458789.png)

整个项目的架构：

![image-20211116212542659](https://gitee.com/huangwei0123/image/raw/master/img/image-20211116212542659.png)

Cache Control响应头

**Cache Control状态标志着缓存的策略**

- private：客户端可以缓存
- public：客户端和代理服务器都可以缓存（代理服务器指的是从客户端到服务器经过所有的中间服务器结点，比如nginx,CDN,正向代理服务器等）
- max-age=xxx：缓存的内容将在xxx秒后失效
- no-cache：强制向服务端再验证一次（客户端缓存在本地，下次使用缓存时要向服务器请求验证是否可以使用缓存）
- no-store：不缓存请求的任何返回内容
  

![image-20211116212902369](https://gitee.com/huangwei0123/image/raw/master/img/image-20211116212902369.png)

客户端向服务器验证是如何做的呢？

**有效性判断**

- ETag：资源唯一标识

​	将请求进行MD5或hash的加密，生成一串资源唯一标识符

​	下次请求时，发送HTTP请求带上ETag，与服务器本地关于ETag做验证，符合就返回`状态码304(NOT Modified)` ，表示缓存客户端可以直接使用

- If-None-Match：客户端发送的匹配ETag的标识符
- Last-modified：资源最后被修改的时间
- if-Modified-Since：客户端发送的匹配资源最后修改时间的标识符



**整个客户端向浏览器请求流程如下**：

![image-20211116213418099](F:\java书籍\Family\文章\秒杀项目.assets\image-20211116213418099.png)

首先请求用户资源，

1、先判断URL本地是否有缓存，如果没有直接向服务器请求，然后返回。

2、如果有，判断缓存的过期时间（max-age），没有过期，直接使用缓存资源

3、如果有max-age但过期，则优先判断ETag：有的话向服务器请求if-None-Match，请求带上ETag

4、没有ETag，判断是否有Last-modified，然后向服务器请求If-modified-since（客户端发送的匹配资源最后修改时间如果早于资源修改的时间Last-modified，则表示无效，已被修改，如果晚于则有效）

5、服务器返回的304表示资源未被修改，本地缓存可以直接使用；如果返回200，表示资源被修改，向服务器发起请求；

#### 2、浏览器的三种刷新方式

1、回车刷新或者a标签：看cache-control对应的max-age是否有效，有效就直接使用本地缓存，如果cache-control为no-cache，则进入`缓存协商逻辑`（去判断ETag或者Last-modified这种方式）

2、F5刷新或者Command+R刷新：去掉cache-control中的max-age或者直接设置为0，然后进入`缓存协商逻辑`

3、强制刷新ctrl+F5或者Command+shift+R刷新：去掉cache-control和协商头（带ETage或Last-Modified），强制刷新，从服务器获取资源。

**缓存协商机制：比较last-modified和ETag到服务端，若服务端判断没变化则304不返回数据，否则200返回数据**

#### 3、静态资源CDN部署策略

如果静态文件（CSS、JS、img）文件名不变，采用max-age设置缓存时间后，如果在缓存有效期内发生版本更新，比如**重大故障**或者更新，如果全部是让用户来手动刷新浏览器，清缓存，这样体验不好，参考下面部署方式：

1、**css,js,img等元素使用带版本号部署，例如a.js?v=1.0不便利，且维护困难**（如果单纯改某个文件版本，其他文件是否更新版本号会难以维护）

html内嵌css,js,img这些资源，必须设置成`no-cache`，向服务器做缓存协商机制。html一般采用**强推**的概念，可以设置max-age，但每次请求都会让CDN全部失效，然后回源，这样将max-age设置一个短的时间后，用户就有版本更新

2、**css,js,img等元素使用带摘要部署：例如a.js?v=45edw存在先部署html还是先部署资源的覆盖问题；**

给资源文件名后加一个部署摘要（一段字符串，如果文件没变化，摘要也不改变），但会存在问题。

1） 情况1-先部署资源文件后部署html

某个js文件发生变化，更改摘要后如果js先部署，js会覆盖老版本，此时html引用的还是老js，有可能导致不兼容问题；

2） 情况2-先部署html后部署资源文件

先部署html会引用新的js,而此时服务器还是老的js等，容易出错

3、**（推荐）css,js,img等元素使用摘要做文件名部署，例如45edw.js,新老版本并存，且可回滚，资源部署完成后再部署html；**

#### 4、全页面静态化是怎么实现的？

html,css,js静态资源cdn化 -->js ajax动态请求cdn化（将请求变成静态文件发送到cdn）–>全页面静态化

**定义**：在服务端完成html，css，甚至js的load渲染成纯html文件后直接以静态资源的方式部署到cdn上

**phantomjs**
首先phantomjs是一个无头浏览器，可以借助其模拟webkit js 的执行

- 修改需要全页面静态化的实现，采用initView和hasInit方式防止多次初始化
- 编写对应轮询生成内容方式
- 将全静态化页面生成后推送到cdn
- **总结：经过全页面静态化以后，从以前刷新ajax请求填充到html这个过程变成了已经执行好的静态html页面**

在项目里面就是：

1、将getItem.html中的 获取商品详情的ajax操作在服务端/爬虫端执行掉

2、执行完成后，依赖于爬虫生成一个已经将数据加载好的静态资源文件（执行了里面的reloadDom()方法）

3、将静态资源文件部署到CDN上，完成全页面静态化操作

```javascript
var page = require("webpage").create();
var fs = require("fs");
// 类似导包一样的操作
page.open("http://miaoshaserver/resource/getitem.html?id=6",function(status){
    console.log(status);
    var isInit = "0";
    // 要设置延迟时间，先要将css和js加载完，才会去给你发请求然后写入文件
    setInterval(function(){
        if(isInit != "1"){
            page.evaluate(function(){
               initView(); 
            });
            isInit = page.evaluate(function(){
                return hasInit();
            });
        }else {
             // 将执行上述请求后的静态文件，以页面的方式写出到getItemPhantom.html
        	fs.write("getItemPhantom.html",page.content,"w");
        	phantom.exit();
        }
       
    },1000);
})


//但是会出现刷新后还是会发出ajax请求，这是为什么呢？
//是因为当js中的reloadDom()已经在我们的无头浏览器phantom中执行一次后，用户用真浏览器打开后，js又被执行了一次，我们需要使用initView和hasInit的方式来控制

//在getItem.html中
<input type='hidden' id='isInit' value='0'>
function hasInit(){
    var isInit = $("#isInit").val();
	return isInit;
}

function setHasInit(){
    $("#isInit").val("1");
}

function initView(){
    var isInit = hasInit();
    if(isInit == "1"){
        return;
    }
    //要执行的ajax请求代码
    
    //无头浏览器做完后，将初始化值设置为1，用户浏览器打开的时候就不会去触发这个ajax请求了
    setInit();
}
```

## 4、交易流程优化

#### 1、交易性能瓶颈

在交易中流程中，我们首先要对**用户信息表**和**密码**得到`UserModel`,然后是**商品信息**、**商品库存**、**商品活动表**进行数据库查询得到`ItemModel`来进行**用户风控策略**和**活动校验策略**，最后对商品库存执行**-1** `update`操作，创建**订单信息操作**和**增加改商品销量**等多次**数据库的I/O**,并且，减库存操作还存在**行锁阻塞**下单接口并发性能很低。

- 交易验证完全依赖数据库
- 库存行锁
- 后置处理逻辑

![image-20211117092532505](https://gitee.com/huangwei0123/image/raw/master/img/image-20211117092532505.png)

#### 2、交易验证优化

- **用户风控策略优化**：策略缓存模型化

在开始交易后，针对活动实时信息和用户实时信息的验证，目的是为了风控策略，检查用户账号是否异常，是否异地登陆，**策略是：通过异步的方式将用户模型写入缓存，与实时信息做一致性检验，做到风控策略**

思路很简单，就是先从Redis里面获取用户信息，没有再去数据库里查，并存到Redis里面。`UserService`新开一个`getUserByIdInCache`的方法。

```java
 public UserModel getUserByIdInCache(Integer id) {
        UserModel userModel = (UserModel) redisTemplate.opsForValue().get("user_valite_"+id);
        if (userModel ==null){
             userModel = this.getUserById(id);
             redisTemplate.opsForValue().set("user_valite_"+id,userModel);
             redisTemplate.expire("user_valite_"+id,10,TimeUnit.MINUTES);
        }
        return userModel;
    }
```

- **活动校验策略优化**：引入活动发布流程，模型缓存化，紧急下线能力

跟用户校验类似，`ItemService`新开一个`getItemByIdInCache`方法。

```java
public ItemModel getItemByIdInCache(Integer id) {
        ItemModel itemModel = (ItemModel) redisTemplate.opsForValue().get("item_validate_"+id);
        if (itemModel == null){
            itemModel = this.getItemById(id);
            redisTemplate.opsForValue().set("item_validate_"+id,itemModel);
            //给缓存设置10分钟的有效时间
            redisTemplate.expire("item_validate_"+id,10, TimeUnit.MINUTES);
        }
        return itemModel;
    }
```

实时活动的缓存存在一个问题：如果后台修改活动信息(修改活动结束时间)，但redis的缓存还处于正常有效期，用户依然可以以活动价格秒杀商品，因此需要有**紧急下线**的能力。

对应的策略是：在活动开始前半个小时发布活动，对**缓存预热**，**同时后台设计一个紧急下线的接口，清除redis缓存，那么用户下单时就会去数据库查询活动的最新信息了**

```java
public void publishPromo(Integer promoId) {
        //通过id获取秒杀活动
        PromoDO promoDO = promoDOMapper.selectByPrimaryKey(promoId);
        if (promoDO.getItemId()==null || promoDO.getItemId().intValue()==0){
            return;
        }
        //默认这段逻辑内，库存是不会变化的。因为在获取某个商品的秒杀活动的同时，该商品也可能会被售卖。
        //库存发生了变化，同步到缓存内的数据就和数据库不一致，最终导致缓存和数据库库存数量的不一致。
        ItemModel itemModel = itemService.getItemByIdInCache(promoDO.getItemId());
        //将库存同步到redis内
        //手动发布 秒杀活动
        redisTemplate.opsForValue().set("promo_item_stock_"+itemModel.getId(),itemModel.getStock());

        //将大闸的限制数字设置到redis中
        redisTemplate.opsForValue().set("promo_door_count_"+promoId,itemModel.getStock().intValue() * 5);
    }
```

#### 3、活动缓存优化(重点)

- **索引优化**（Mysql弱点）

对于之前下单减库存的操作，我们是直接执行`update stock set stock = stock -#{amount} where item_id = #{itemId} and stock >= #{amount}`这条`SQL`语句的，但是此**where条件item_id是没有索引**的，那么就会直接**锁表**，降低了性能，故我们对其添加唯一索引`alter table item_stock add unique index item_stock_index(item_id);`此时为**锁行**。

在更新操作时，如果条件没有索引会直接锁表（Mysql排它锁），如果走了索引会定位到具体的行（）。

- **库存缓存优化**（方案一）

方案是：我们要将扣减库存的操作发生在缓存而不是数据库中，缓存的扣减时间相对较少

首先要：（1）活动发布同时同步库存进缓存

PromoServiceImpl实现类(默认获取活动id以及商品信息的时候库存不发生变化)

```java
@Override
public void publishPromo(Integer promoId) {
    //通过活动id获取活动
    PromoDO promoDO = promoDOMapper.selectByPrimaryKey(promoId);
    if(promoDO.getItemId()==null || promoDO.getItemId().intValue()==0) {
        return;
    }
    ItemModel itemModel = itemService.getItemById(promoDO.getItemId());

    //将库存同步到redis内
    redisTemplate.opsForValue().set("promo_item_stock_"+itemModel.getId(),itemModel.getStock());

}
```

前端写发布活动的controller接口

```java
@RequestMapping(value = "/publishpromo",method = RequestMethod.GET) //浏览时服务端用GET请求
@ResponseBody
public CommonReturnType publishpromo(@RequestParam(name = "id") Integer id) {
    promoService.publishPromo(id);
    return CommonReturnType.create(null);
}
```

更新ItemServiceImpl里更新redis减库存的操作

```java
//减缓存库存
long result = redisTemplate.opsForValue().increment("promo_item_stock_"+itemId,amount.intValue()*-1);

if(result > 0 ) {
    //更新缓存库存成功
    return true;
}else {
    //更新缓存库存失败
    return false;
}
```

做到**缓存减库存操作**，但这样还存在数据库记录**不一致**的情况

在进行秒杀活动时，在短时间内有大量的请求打在MySQL上，因此我们使用Redis缓存技术减少同一时间MySQL服务器的压力，在发布活动时，我们将MySQL中的库存同步到Redis中，**但是下单后**，我们要将缓存的库存信息同步到数据库中，这就需要**异步消息队列**——也就是**RocketMQ**。

RocketMQ是一个异步消息队列。主要可以用来**解耦**、**异步**、**削峰**

本项目中主要应用到的是异步和削峰，本项目是个秒杀项目，考虑到在活动开启时，大量用户购买商品对服务器造成巨大压力，我们使用RocketMQ进行**异步**处理，和**削峰**操作。

**异步：**在Redis上库存更改后，我们不直接更改Mysql，而是以异步消息的方式去进行缓存，后续也能应用到商品销量上，**对一些时序性要求不高的**，我们进行一个功能的拆分。

**削峰：**以异步消息队列的方式进行缓存，当秒杀活动结束，用户请求大幅度降低，我们服务器减少压力的时候，再按照数据库承受量对消息进行消费。

- **异步同步数据库（方案二）**

（1）活动发布同步库存进缓存

（2）下单交易减缓存库存

（3）异步消息扣减数据库内存

采用异步消息队列的方式，**将异步扣减的消息同步给消息的consumer端，并由消息的consunmer端完成数据库扣减的操作**

> 每次下单都从缓存中扣取库存，暂时没有同步入数据库，此时没有跟数据库同步，我们引用RocketMQ

新建一个`MQProducer` 生产者类，通过`@PostContruct`初始化生产者

**`@PostConstruct`该注解被用来修饰一个非静态的`void（）`方法。被`@PostConstruct`修饰的方法会在服务器加载`Servlet`的时候运行，并且只会被服务器执行一次。`PostConstruct`在构造函数之后执行，`init（）`方法之前执行**

```java
public class MqProducer {
    private DefaultMQProducer producer;
    //即是IP:9867
    @Value("${mq.nameserver.addr}")
    private String nameAddr;
    //即是stock
    @Value("${mq.topicname}")
    private String topicName;
   
    @PostConstruct
    public void init() throws MQClientException {
        //Producer初始化，Group对于生产者没有意义，但是消费者有意义
        producer=new DefaultMQProducer("producer_group");
        producer.setNamesrvAddr(nameAddr);
        producer.start();
    }
}
```

通过`asyncReduceStock`方法实现异步扣减库存。

```java
//异步库存扣减的消息
//此方法非事务性，什么是事务性呢？我们要保证只要数据库事务提交了，对应的消息是必定可以发送成功的，
//数据库内事务回滚了，消息必定不发送，数据库状态未知，那状态必定是处理中，等待数据库的提交或者回滚
public boolean asyncReduceStock(Integer itemId, Integer amount) {
    //声明用于投放消息的Map
    Map<String, Object> bodyMap = new HashMap<>();
    //使用一个HashMap来存储，我们所需要的商品id和购买的数量
    bodyMap.put("itemId", itemId);
    bodyMap.put("amount", amount);
    //再通过消息去发送到要执行的业务那里
    Message message = new Message(topicName, "increase",
                                  JSON.toJSON(bodyMap).toString().getBytes(Charset.forName("UTF-8")));
    try {
        producer.send(message);
    } catch (MQClientException e) {
        e.printStackTrace();
        return false;
    } catch (RemotingException e) {
        e.printStackTrace();
        return false;
    } catch (MQBrokerException e) {
        e.printStackTrace();
        return false;
    } catch (InterruptedException e) {
        e.printStackTrace();
        return false;
    }
    return true;
}
```

新建`MqConsumer`类，与`MqProducer`类类似，也有一个`init`方法，实现**异步扣减库存**的逻辑。

```java
@Component
public class MqConsumer {

    private DefaultMQPushConsumer consumer;

    @Value("${mq.nameserver.addr}")
    private String nameAddr;

    @Value("${mq.topicname}")
    private String topicName;

    @Autowired
    private ItemStockDOMapper itemStockDOMapper;

    @PostConstruct
    public void init() throws MQClientException {
        consumer = new DefaultMQPushConsumer("stock_consumer_group");
        consumer.setNamesrvAddr(nameAddr);
        //描述清楚这个消费者 到底是监听哪个订阅topic消息
        consumer.subscribe(topicName,"*");

        //当消息传递过来以后，怎么去处理
        consumer.registerMessageListener(new MessageListenerConcurrently() {
            //ConsumeConcurrentlyStatus  中有2个常量，一个是返回success  另一个是
            @Override
            public ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> msgList, ConsumeConcurrentlyContext consumeConcurrentlyContext) {
                //实现库存到数据库内扣减的逻辑
                Message message = msgList.get(0);
                String JsonString = new String(message.getBody());
                //将返回回来的消息的body进行解析，转化成一个组装前的Map集合，用于拿到数据
                Map<String,Object> map = JSON.parseObject(JsonString, Map.class);
                Integer itemId = (Integer) map.get("itemId");
                Integer amount = (Integer) map.get("amount");

                //成功进行数据的见库存操作，缓存数据库一致化
                itemStockDOMapper.decreaseStock(itemId,amount);

                //如果返回成果，mq就会认定这条消息会被消费，下次不会在做投放
                return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;
            }
        });
        consumer.start();
    }
}
```

`ItemService.decreaseStock`方法也要做更改：

```java
public boolean decreaseStock(Integer itemId, Integer amount) {
    long affectedRow=redisTemplate.opsForValue().
        increment("promo_item_stock_"+itemId,amount.intValue()*-1);
    //>0，表示Redis扣减成功
    if(affectedRow>=0){
        //发送消息到消息队列，准备异步扣减
        boolean mqResult = mqProducer.asyncReduceStock(itemId,amount);
        if (!mqResult){
            //消息发送失败，需要回滚Redis
            redisTemplate.opsForValue().increment("promo_item_stock_"+itemId,amount.intValue());
            return false;
        }
        return true;
    } else {
        //Redis扣减失败，回滚
        redisTemplate.opsForValue().increment("promo_item_stock_"+itemId,amount.intValue());
        return false;
    }
}
```

看似没有问题了，但是细心会发现，我们对于发出去的消息不能进行消费成功或者失败的处理。

**存在的问题**

1. 如果发送消息失败，只能回滚Redis。
2. 对于发出去的消息，直接成功，没有回滚
3. 下单过程中出现异常无法回滚数据库

所以我们引入**事务型消息**

> 将上述decreaseStock 中Redis回补 和消息的发送 功能抽离开来，使订单成功之后再进行异步消息的发送。

ItemServiceImpl

```java
@Transactional(rollbackFor = Exception.class)
public boolean decreaseStock(Integer itemId, Integer amount) {
    long affectedRow=redisTemplate.opsForValue().
                increment("promo_item_stock_"+itemId,amount.intValue()*-1);
    // >0，表示Redis扣减成功
    if(affectedRow>=0){
        // 抽离了发送异步消息的逻辑
        return true;
    } else {
        // Redis扣减失败，回滚
        increaseStock(itemId, amount)
        return false;
    }
}

public boolean increaseStock(Integer itemId, Integer amount) {
    redisTemplate.opsForValue().increment("promo_item_stock_"+itemId,amount.intValue());
    return true;
}

// ItemService
public boolean asyncDecreaseStock(Integer itemId, Integer amount) {
    return mqProducer.asyncReduceStock(itemId, amount);
}
```

OrderServiceImpl

```java
// 在下单service中，等执行完最后一步才发送异步消息
@Transactional
.....


    //异步更新库存
        /*
        为什么写在这这里？
        1、因为itemServiceImpl中使用了落单减库存的操作，是一个大事务，然后其中减库存是个小事务，如果大事务中
        有方法出错回滚，那么小事务中会发送扣减redis，和发送消息去扣减库存，会导致秒杀商品卖不完。导致堆积
        2、只有确保大事务中所有条件全部执行，没有回滚才能去数据库减库存。所以才写到这里。
         */
    boolean mqResult=itemService.asyncDecreaseStock(itemId,amount);
if(!mqResult){
    //回滚redis库存
    itemService.increaseStock(itemId,amount);
    throw new BusinessException(EmBusinessError.MQ_SEND_FAIL);
}
```

**问题**：Spring的**Transactional**标签，只有等到整个方法返回的时候，才会去commit提交，

会不会因为**网络异常**或者是因为**磁盘不足**，导致提交失败呢? 

结果：数据库回滚，但是Redis库存已扣，还是**无法保证一致性**。我们需要在**事务提交成功后**，**再发送异步消息**

这样的问题是存在的，**借助**Spring给我们提供了`TransactionSynchronizationManager.registerSynchronization`方法，这个方法的传入一个`TransactionSynchronizationAdapter`的匿名类，通过`afterCommit`方法，在**事务提交成功后**，执行**发送消息操作**。

```java
TransactionSynchronizationManager.registerSynchronization(new TransactionSynchronizationAdapter() {
    @Override
    public void afterCommit() {
        boolean mqResult = itemService.asyncDecreaseStock(itemId, amount);
        if (!mqResult){
            itemService.increaseStock(itemId,amount);
            throw new BusinessException(EmBusinessError.MQ_SAND_FAIL);
        }
    }
});
```

**事务型消息的引入**

当`afterCommit()`执行出错则会出现问题，又不能回滚，故引用事务型消息。

发送到消息队列的消息先处于`prepared`状态，当`broker`接受到时，是**不允许消费者消费**的。要先执行`TransactionListener`的`executeLocalTransaction`方法，根据执行结果，**改变事务型消息的状态**，根据这三种状态判断能否消费`COMMIT,ROLLBACK UNKNOWN`。

```java
//使用事务型异步消息扣减库存
public boolean transactionAsyncReduceStock(Integer userId, Integer itemId,
                                           Integer promoId, Integer amount, String stockLogId) {
    //声明用于投放消息的Map
    Map<String, Object> bodyMap = new HashMap<>();
    //使用一个HashMap来存储，我们所需要的商品id和购买的数量,以及库存的流水
    bodyMap.put("itemId", itemId);
    bodyMap.put("amount", amount);
    bodyMap.put("stockLogId", stockLogId);

    //用来向事务型消息中传递创建订单的参数,检查是否能被消费
    Map<String, Object> argsMap = new HashMap<>();
    argsMap.put("itemId", itemId);
    argsMap.put("amount", amount);
    argsMap.put("userId", userId);
    argsMap.put("promoId", promoId);
    argsMap.put("stockLogId", stockLogId);
    //再通过消息去发送到要执行的业务那里
    Message message = new Message(topicName, "increase",
                                  JSON.toJSON(bodyMap).toString().getBytes(Charset.forName("UTF-8")));
    TransactionSendResult transactionSendResult = null;
    try {
        transactionSendResult = transactionMQProducer.sendMessageInTransaction(message, argsMap);
        //事务性消息有个二级提交的概念，当消息发送出去后，我们的msgbroker可以收到我们的这条消息
        //但是 它的状态不是可被消费，而是prepared的状态，不会被消费者进行消费,而是会去执行executeLocalTransaction这个方法
    } catch (MQClientException e) {
        e.printStackTrace();
        return false;
    }
    if (transactionSendResult.getLocalTransactionState() == LocalTransactionState.ROLLBACK_MESSAGE) {
        return false;
    } else if (transactionSendResult.getLocalTransactionState() == LocalTransactionState.COMMIT_MESSAGE) {
        return true;
    } else {
        return false;
    }
}
```

broker收到`prepare`消息后，会执行`TransactionListener`的`executeLocalTransaction`方法，来判断能否被消费：

```java
transactionMQProducer.setTransactionListener(new TransactionListener() {
    @Override
    public LocalTransactionState executeLocalTransaction(Message message, Object args) {
        //真正要做的事  eg:创建订单
        Integer userId = (Integer) ((Map) args).get("userId");
        Integer itemId = (Integer) ((Map) args).get("itemId");
        Integer amount = (Integer) ((Map) args).get("amount");
        Integer promoId = (Integer) ((Map) args).get("promoId");
        String stockLogId = (String) ((Map) args).get("stockLogId");
        try {
            orderService.createOrder(userId, itemId, promoId, amount, stockLogId);
        } catch (BusinessException e) {
            //如果创建订单出现异常，那么将事务回滚
            e.printStackTrace();
            return LocalTransactionState.ROLLBACK_MESSAGE;
        }
        return LocalTransactionState.COMMIT_MESSAGE;
    }
```

**问题**：当执行`orderService.createOrder`后，突然**又宕机了**，根本没有返回，这个时候事务型消息就会进入`UNKNOWN`状态，我们需要处理这个状态。

这中间可能会存在一个问题，生产者本地事务成功后，发送事务确认消息到broker上失败了怎么办？

这个时候意味着消费者无法正常消费到这个消息。所以RocketMQ提供了**消息回查机制**（**LocalTransactionState checkLocalTransaction(MessageExt messageExt**) 方法

如果事务消息**一直处于中间状态**，**broker**会发起重试去查询broker上这个**事务的处理状态**。**一旦发现事务处理成功，则把当前这条消息设置为可见。**
![image-20211117180246280](https://gitee.com/huangwei0123/image/raw/master/img/image-20211117180246280.png)

在匿名类`TransactionListener`里面，还需要覆写`checkLocalTransaction`方法，这个方法就是用来处理`UNKNOWN`状态的。应该怎么处理？

回调checkLocalTransaction函数时，**无法仅仅通过itemId和amount来确定库存是否扣减成功**

这就需要引入**库存流水**，通过流水可以查看和进行相应的操作。(检查消息发送的状态)

**引入库存流水**

数据库新建一张`stock_log`的表，用来记录库存流水

```sql
CREATE TABLE `stock_log` (
  `stock_log_id` varchar(64) COLLATE utf8_unicode_ci NOT NULL COMMENT '用来记录唯一性的库存的流水',
  `item_id` int(11) NOT NULL,
  `amount` int(11) NOT NULL DEFAULT '0',
  `status` int(11) NOT NULL DEFAULT '0' COMMENT '为1表示初始状态，2表示下单扣减库存成功，3表示下单回滚',
  PRIMARY KEY (`stock_log_id`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci ROW_FORMAT=COMPACT
```

添加一个`ItemService.initStockLog`方法

```java
@Transactional
//初始化对应的订单流水
public String initStockLog(Integer itemId, Integer amount) {
    StockLogDO stockLogDO = new StockLogDO();
    stockLogDO.setItemId(itemId);
    stockLogDO.setAmount(amount);
    stockLogDO.setStockLogId(UUID.randomUUID().toString().replace("-",""));
    //默认将库存流水状态设置为1  1是初始化状态 2是下单成功扣减库存 3是下单失败事务回滚
    stockLogDO.setStatus(1);
    stockLogDOMapper.insertSelective(stockLogDO);
    //通过返回流水的id来判断流水的状态？
    return stockLogDO.getStockLogId();
}
```

```
流水状态 1 表示Prepare 2 表示 成功 3 表示需要回滚
1. 
2. 如果Redis扣减库存、订单入库、销量增加的操作完成则更新流水的状态  
3. 根据status状态判断
```

在发送异步消息队列前，生成一个流水



**事务消息** 去检查当前 **消息的状态**（根据库存流水判断,如果是中间状态先去执行业务逻辑）

```java
@Override
public LocalTransactionState checkLocalTransaction(MessageExt message) {
    //根据是否扣减库存成功，来判断返回commit、rollback还是继续unkown
    String JsonString = new String(message.getBody());
    //将返回回来的消息的body进行解析，转化成一个组装前的Map集合，用于拿到数据
    Map<String, Object> map = JSON.parseObject(JsonString, Map.class);
    Integer itemId = (Integer) map.get("itemId");
    Integer amount = (Integer) map.get("amount");
    //但是你怎么通过itemId、amount知道该订单的一个流水状态呢？
    //通过库存的一个流水，来获取订单的一个状态
    String stockLogId = (String) map.get("stockLogId");
    StockLogDO stockLogDO = stockLogDOMapper.selectByPrimaryKey(stockLogId);
    if (stockLogDO == null) {
        return LocalTransactionState.UNKNOW;
    }
    Integer status = stockLogDO.getStatus();
    if (status == 2) {
        return LocalTransactionState.COMMIT_MESSAGE;
    } else if (status == 1) {
        return LocalTransactionState.UNKNOW;
    }
    return LocalTransactionState.ROLLBACK_MESSAGE;
}
```

如果消息发送成功，但是**执行业务逻辑**（创建订单失败），将库存流水状态置为3，事务型消息回滚

```java
transactionMQProducer.setTransactionListener(new TransactionListener() {
    @Override
    public LocalTransactionState executeLocalTransaction(Message message, Object args) {
        //真正要做的事  eg:创建订单
        Integer userId = (Integer) ((Map) args).get("userId");
        Integer itemId = (Integer) ((Map) args).get("itemId");
        Integer amount = (Integer) ((Map) args).get("amount");
        Integer promoId = (Integer) ((Map) args).get("promoId");
        String stockLogId = (String) ((Map) args).get("stockLogId");
        try {
            orderService.createOrder(userId, itemId, promoId, amount, stockLogId);
        } catch (BusinessException e) {
            //如果创建订单出现异常，那么将事务回滚
            e.printStackTrace();
            //设置对应StockLog为回滚状态 status为3
            StockLogDO stockLogDO = stockLogDOMapper.selectByPrimaryKey(stockLogId);
            stockLogDO.setStatus(3);
            stockLogDOMapper.updateByPrimaryKeySelective(stockLogDO);
            return LocalTransactionState.ROLLBACK_MESSAGE;
        }
        return LocalTransactionState.COMMIT_MESSAGE;
    }
```

#### 4、小结

事务型消息被提交以后，会在`broker`里处于`prpare`状态也就是`UNKNOWN`，**等待被消费端消费**，或是回滚。`prepare`状态下会执行

```java
orderService.createOrder(userId, itemId, promoId, amount, stockLogId);
```

此时后续会有2种情况了

1、`createOrder`执行完**没有宕机**，要么**执行成功**，要么**抛出异常**。**执行成功**，那么就说明下单成功了，订单入库了，Redis里的库存扣了，销量增加了，**等待着异步扣减库存**，所以将事务型消息的状态，从`UNKNOWN`变为`COMMIT`，这样消费端就会消费这条消息，异步扣减库存。**抛出异常**，那么订单入库、Redis库存、销量增加，就会被数据库回滚，此时去异步扣减的消息，就应该“丢弃”，所以发回`ROLLBACK`，进行回滚。

2、`createOrder`执行完**宕机**了，那么这条消息会是`UNKNOWN`状态，这个时候就需要在`checkLocalTransaction`进行处理。如果`createOrder`执行完毕，此时`stockLog.status==2`，就说明下单成功，需要去异步扣减库存，所以返回`COMMIT`。如果`status==1`，说明下单还未完成，还需要继续执行下单操作，所以返回`UNKNOWN`。如果`status==3`，说明下单失败，需要回滚，不需要异步扣减库存，所以返回`ROLLBACK`。

#### 5、库存售罄

当库存售罄时，还会**初始化库存流水**这个操作，导致之后**下单失败**，所以对库存售罄的情况做一个处理

- 库存售罄标识
- 售罄后不去操作后续流程
- 售罄后通知各系统售罄
- 回补上新

在ItemServiceImpl的**减缓存库存**中，若result == 0 ，redis内打上已售罄标识。在之后初始化库存流水之前，判断redis内是否有此key，如果有，直接返回库存不足

```java
@Transactional(rollbackFor = Exception.class)
//如果说外部已经有了事务，那么@Transactional将会沿用外部的事务，和外部事务同时成功同时失败
public boolean decreaseStock(Integer itemId, Integer amount) {
    long result = redisTemplate.opsForValue().increment("promo_item_stock_"+itemId,amount.intValue()* -1);

    if (result > 0){
        return true;
    }else if (result == 0 ){
        //设置库存售罄的标志
        redisTemplate.opsForValue().set("promo_item_stock_invalid_"+itemId,"true");
        return false;
    }else {
        //说明更新库存失败
        increaseStock(itemId,amount);
        return false;
    }
}

public boolean increaseStock(Integer itemId, Integer amount){
    //逻辑就是固定把redis所扣减的库存补回来，然后返回
    redisTemplate.opsForValue().increment("promo_item_stock_"+itemId,amount.intValue());
    return true;
}
```

OrderController在加入库存流水init状态前判断是否已售罄

```java
//判断是否库存已售罄，若对应的售罄key存在，直接返回下单失败
if(redisTemplate.hasKey("promo_item_stock_invalid_"+itemId)){
    throw new BusinessException(EmBusinessError.STOCK_NOT_ENOUGH);
}
```

## 5、流量削峰

- 秒杀下单接口容易被脚本不停的刷 --- 只要知道它自己的token 和 秒杀地址即可
- 秒杀验证的逻辑和秒杀下单强关联，代码冗余高
- 秒杀验证逻辑复杂

秒杀令牌使用：

- 秒杀接口需要秒杀令牌才能进入
- 秒杀令牌由秒杀活动模块生成
- 秒杀活动模块对秒杀令牌生成全权处理，逻辑收口
- 秒杀下单前需要先获得秒杀令牌

#### 1、秒杀令牌的实现

在poromoServiceImpl下

1. 先校验活动商品
2. 商品是否在活动状态下，在秒杀则能生成，否则不生成
3. 对用户和商品信息的校验
4. 根据秒杀活动id，商品id，用户id，生成秒杀令牌token

```java
public String generateSecondKillToken(Integer promoId,Integer itemId,Integer userId) {

    PromoDO promoDO = promoDOMapper.selectByPrimaryKey(promoId);

    //promoDo(dataObject) -> PromoModel
    PromoModel promoModel = convertFromDataObject(promoDO);
    if(promoModel == null) {
        return null;
    }
    //判断当前时间是否秒杀活动即将开始或正在进行
    DateTime now = new DateTime();
    if(promoModel.getStartDate().isAfterNow()) {
        promoModel.setStatus(1);
    }else if(promoModel.getEndDate().isBeforeNow()) {
        promoModel.setStatus(3);
    }else {
        promoModel.setStatus(2);
    }
    //判断活动是否正在进行
    if(promoModel.getStatus().intValue()!=2){
        return null;
    }

    //判断item信息是否存在
    ItemModel itemModel = itemService.getItemByIdInCache(itemId);
    if(itemModel == null) {
        return null;
    }
    //判断用户信息是否存在
    UserModel userModel = userService.getUserByIdInCache(userId);
    if(userModel == null) {
        return null;
    }
    //生成token并且存入redis设置5分组有效期
    String token = UUID.randomUUID().toString().replace("-","");
    redisTemplate.opsForValue().set("promo_token_"+promoId+"_userid_"+userId+"_itemid_"+itemId,token);
    redisTemplate.expire("promo_token_"+promoId+"_userid_"+userId+"_itemid_"+itemId,5, TimeUnit.MINUTES);

    return token;
}
```

在OrderController中定义/generatetoken 路径下生成秒杀令牌，调用在poromoServiceImpl下的generateSecondKillToken()

```java
//生成秒杀令牌
@PostMapping(value = "/generatetoken", consumes = {CONTENT_TYPE_FORMED})
@ResponseBody
public CommonReturnType generateToken(@RequestParam("itemId") Integer itemId,
                                      @RequestParam("promoId") Integer promoId,
                                      @RequestParam("verifyCode")String verifyCode) throws BusinessException {

    String token = request.getParameterMap().get("token")[0];
    if (StringUtils.isEmpty(token)) {
        throw new BusinessException(EmBusinessError.USER_NOT_LOGIN, "用户还未登录,不能下单");
    }
    //从redis中拿到对应uuid的userModel
    UserModel userModel = (UserModel) redisTemplate.opsForValue().get(token);
    if (userModel == null) {
        throw new BusinessException(EmBusinessError.USER_NOT_LOGIN, "用户还未登录,不能下单");
    }

    //验证 验证码的有效性
    String redisVerifyCode = (String)redisTemplate.opsForValue().get("verify_code_" + userModel.getId());
    if (StringUtils.isEmpty(redisVerifyCode)){
        throw new BusinessException(EmBusinessError.PARAMETER_VALIDATION_ERROR,"请求非法");
    }
    if (!redisVerifyCode.equalsIgnoreCase(verifyCode)){
        throw new BusinessException(EmBusinessError.PARAMETER_VALIDATION_ERROR,"请求非法，验证码错误");
    }

    //获取秒杀访问令牌
    String promoToken = promoService.generateSecondKillToken(promoId, itemId, userModel.getId());

    //非法请求一般走这个地方
    if (promoToken == null) {
        throw new BusinessException(EmBusinessError.PARAMETER_VALIDATION_ERROR, "生成秒杀令牌失败");
    }
    return CommonReturnType.create(promoToken);
}
```

之后在下单界面可以省去用户商品和活动的校验，直接获取秒杀令牌如果成功即可

```java
//校验秒杀令牌是否正确
if (promoId != null) {
    String inRedisPromoToken = (String) redisTemplate.opsForValue().get("promo_token_"+promoId+"_userId_"+userModel.getId()+"_itemId_"+itemId);
    //如果 redis 中的key 失效，为null 前端传回来的token 也为空,则会出发 秒杀令牌正常，显然不合理
    //可能会造成，不同用户对同一商品的缓存化一致的问题，所以我们在缓存key的时候 需要加上用户标志
    if (inRedisPromoToken == null) {
        throw new BusinessException(EmBusinessError.PARAMETER_VALIDATION_ERROR, "秒杀令牌校验失败");
    }
    if (!StringUtils.equals(promoToken, inRedisPromoToken)) {
        throw new BusinessException(EmBusinessError.PARAMETER_VALIDATION_ERROR, "秒杀令牌校验失败");
    }
}
```

**问题**：如果下单人数过多，令牌发送过多。影响性能

**解决 --- 秒杀大闸** ： 通过库存的多少来限制令牌的数量。(令牌数量为库存五倍)



#### 2、秒杀大闸原理及实现

- 依靠秒杀令牌的授权原理定制化发牌逻辑，做大闸功能
- 根据秒杀商品初始化库存颁发对应数量令牌，控制大闸流量
- 用户风控策略前置到秒杀令牌发放中
- 库存售罄判断前置到秒杀令牌发放中

设置一个以秒杀商品初始库存x倍数量作为秒杀大闸，若超出这个数量，则无法发放秒杀令牌

```java
//将大闸的限制数字设置到redis中
redisTemplate.opsForValue().set("promo_door_count_"+promoId,itemModel.getStock().intValue() * 5);
```

缺陷：

- 浪涌流量涌入后系统无法应对
- 多库存，多商品等令牌限制能力弱



#### 3、队列泄洪原理

- 排队有些时候比并发更高效（例如redis单线程模型，innodb mutex key等）

并发时遇到行锁或者互斥锁的竞争，如果一个线程在运行中遇到锁，那么我就要退出执行，由cpu调度另一个线程，然后又遇到锁，又要进行上下文的切换

innodb在数据库操作时要加上行锁，mutex key是竞争锁，阿里sql优化了mutex key结构，当判断存在多个线程竞争锁时，会设置队列存放SQL语句

- 依靠排队去限制并发流量
- 依靠排队和下游拥塞窗口程度调整队列释放流量大小
- 支付宝银行网关队列举例

支付宝有多种支付渠道，在大促活动开始时，支付宝的网关有上亿级别的流量，银行的网关无法支持这种大流量，支付宝会将支付请求放到自己的队列中，根据银行网关可以承受的tps流量调整拥塞窗口，去泄洪

**如果我知道会遇到锁，我不如将其排队，等它执行完，下一个再进行执行**

典型代表：**Redis**，它的set和get都是单线程的，没有cpu切换上下文的开销，然后是基于内存的，故快。

**队列泄洪代码实现**

```java
private ExecutorService executorService;

@PostConstruct
public void init(){
    // 定义一个只有20个可工作线程的线程池
    // executorService = Executors.newFixedThreadPool(20);
    executorService = new ThreadPoolExecutor(
        20,30,1L,TimeUnit.SECONDS,
        new LinkedBlockingQueue<>(10),Executors.defaultThreadFactory(),
        new ThreadPoolExecutor.AbortPolicy()
    );
}
//同步调用线程池的submit方法
//拥塞窗口为20的等待队列，用来队列化泄洪
Future<Object> future = executorService.submit(new Callable<Object>() {
    @Override
    public Object call() throws Exception {
        //加入库存流水init状态
        String stockLogId = itemService.initStockLog(itemId,amount);
        //再去完成对应的下单事务型消息机制
        if(!mqProducer.transactionAsyncReduceStock(userModel.getId(),itemId,promoId,amount,stockLogId)){
            throw new BusinessException(EmBusinessError.UNKNOWN_ERROR,"下单失败");
        }
        return null;
    }
});

try {
    future.get();
} catch (InterruptedException e) {
    throw new BusinessException(EmBusinessError.UNKNOWN_ERROR);
} catch (ExecutionException e) {
    throw new BusinessException(EmBusinessError.UNKNOWN_ERROR);
}
return CommonReturnType.create(null);
}
```

#### 4、队列|本地或者分布式

- 本地：将队列维护在本地内存中
- 分布式：将队列设置到redis内

比如说我们有100台机器，假设每台机器设置20个队列，那我们的拥塞窗口就是2000，

但是由于负载均衡的关系，很难保证每台机器都能够平均收到对应的createOrder的请求，

那如果将这2000个排队请求放入redis中，**每次让redis去实现以及去获取对应拥塞窗口设置的大小**，这种就是**分布式队列**


本地队列的好处就是完全维护在内存当中的，没有网络请求的消耗，只要JVM不挂，应用是存活的，那本地队列的功能就不会失效。

可以使用外部的分布式集中队列，当外部集中队列不可用时或者请求时间超时，可以采用降级的策略，切回本地的内存队列。



## 6、防刷限流

- 掌握验证码生成与验证技术
- 掌握限流原理与实现
- 掌握防黄牛技术

#### 1、验证码技术

- 包装秒杀令牌前置，需要验证码来错峰
- 数学公式验证码生成器

自己定义一个验证码生成器

```java
public class CodeUtil {
    private static int width = 90;// 定义图片的width
    private static int height = 20;// 定义图片的height
    private static int codeCount = 4;// 定义图片上显示验证码的个数
    private static int xx = 15;
    private static int fontHeight = 18;
    private static  int codeY = 16;
    private static char[] codeSequence = { 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R',
                                          'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9' };

    /**
     * 生成一个map集合
     * code为生成的验证码
     * codePic为生成的验证码BufferedImage对象
     * @return
     */
    public static Map<String,Object> generateCodeAndPic() {
        // 定义图像buffer
        BufferedImage buffImg = new BufferedImage(width, height, BufferedImage.TYPE_INT_RGB);
        // Graphics2D gd = buffImg.createGraphics();
        // Graphics2D gd = (Graphics2D) buffImg.getGraphics();
        Graphics gd = buffImg.getGraphics();
        // 创建一个随机数生成器类
        Random random = new Random();
        // 将图像填充为白色
        gd.setColor(Color.WHITE);
        gd.fillRect(0, 0, width, height);

        // 创建字体，字体的大小应该根据图片的高度来定。
        Font font = new Font("Fixedsys", Font.BOLD, fontHeight);
        // 设置字体。
        gd.setFont(font);

        // 画边框。
        gd.setColor(Color.BLACK);
        gd.drawRect(0, 0, width - 1, height - 1);

        // 随机产生40条干扰线，使图象中的认证码不易被其它程序探测到。
        gd.setColor(Color.BLACK);
        for (int i = 0; i < 30; i++) {
            int x = random.nextInt(width);
            int y = random.nextInt(height);
            int xl = random.nextInt(12);
            int yl = random.nextInt(12);
            gd.drawLine(x, y, x + xl, y + yl);
        }

        // randomCode用于保存随机产生的验证码，以便用户登录后进行验证。
        StringBuffer randomCode = new StringBuffer();
        int red = 0, green = 0, blue = 0;

        // 随机产生codeCount数字的验证码。
        for (int i = 0; i < codeCount; i++) {
            // 得到随机产生的验证码数字。
            String code = String.valueOf(codeSequence[random.nextInt(36)]);
            // 产生随机的颜色分量来构造颜色值，这样输出的每位数字的颜色值都将不同。
            red = random.nextInt(255);
            green = random.nextInt(255);
            blue = random.nextInt(255);

            // 用随机产生的颜色将验证码绘制到图像中。
            gd.setColor(new Color(red, green, blue));
            gd.drawString(code, (i + 1) * xx, codeY);

            // 将产生的四个随机数组合在一起。
            randomCode.append(code);
        }
        Map<String,Object> map  =new HashMap<String,Object>();
        //存放验证码
        map.put("code", randomCode);
        //存放生成的验证码BufferedImage对象
        map.put("codePic", buffImg);
        return map;
    }
```

在OrderController中加入生成验证码

```java
@RequestMapping(value = "/generateVerifyCode")
@ResponseBody
public void generateVerifyCode(HttpServletResponse response) throws BusinessException, IOException {

    String token = request.getParameterMap().get("token")[0];
    if (StringUtils.isEmpty(token)) {
        throw new BusinessException(EmBusinessError.USER_NOT_LOGIN, "用户还未登录,不能生成验证码");
    }
    UserModel userModel = (UserModel) redisTemplate.opsForValue().get(token);
    if (userModel == null) {
        throw new BusinessException(EmBusinessError.USER_NOT_LOGIN, "用户还未登录,不能生成验证码");
    }
    //创建文件输出流对象
    Map<String,Object> map = CodeUtil.generateCodeAndPic();
    redisTemplate.opsForValue().set("verify_code_"+userModel.getId(),map.get("code"),10,TimeUnit.MINUTES);
    //写到http的response当中，返回给前端
    ImageIO.write((RenderedImage) map.get("codePic"), "jpeg", response.getOutputStream());
    System.out.println("验证码的值为："+map.get("code"));
}
```

生成秒杀令牌前验证验证码的有效性

```java
//验证 验证码的有效性
String redisVerifyCode = (String)redisTemplate.opsForValue().get("verify_code_" + userModel.getId());
if (StringUtils.isEmpty(redisVerifyCode)){
    throw new BusinessException(EmBusinessError.PARAMETER_VALIDATION_ERROR,"请求非法");
}
if (!redisVerifyCode.equalsIgnoreCase(verifyCode)){
    throw new BusinessException(EmBusinessError.PARAMETER_VALIDATION_ERROR,"请求非法，验证码错误");
}
```



#### 2、限流方案

- 流量远比你想的要多
- 系统活着比挂了要好
- 宁愿只让少数人能用，也不要让所有人不能用

**1、限制并发**

对同一时间固定访问接口的线程数做限制，利用**全局计数器**，在下单接口OrderController处加一个全局计数器，并支持并发操作，当controller在入口的时候，计数器减1，判断计数器是否大于0，在出口时计数器加一，就可以控制同一时间访问的固定。

- **令牌桶算法**

![image-20211122112418830](https://gitee.com/huangwei0123/image/raw/master/img/image-20211122112418830.png)

令牌桶算法可以做到客户端一秒访问10个流量，下一秒就是下一个10个流量，限定某个时刻的最大值

- **漏桶算法**

![image-20211122112611230](https://gitee.com/huangwei0123/image/raw/master/img/image-20211122112611230.png)

漏桶算法的目的用来**平滑网络流量**，没有办法应对突发流量

**限流范围：**

分为**集群限流**和**单机限流**

集群限流顾名思义就是限制整个集群的流量，需要用Redis或者其它中间件技术来做统一计数器，往往会产生性能瓶颈。

单机限流在负载均衡的前提下效果更好。

#### 3、限流代码实现（Guava RateLimit）

RateLimiter没有实现令牌桶内定时器的功能

reserve方法是当前秒的令牌数，如果当前秒内还有令牌就直接返回；若没有令牌，需要计算下一秒是否有对应的令牌，有一个下一秒计算的提前量，使得下一秒请求过来的时候，仍然不需要重复计算

RateLimiter的设计思想比较超前，没有依赖于人为定时器的方式，而是将**整个时间轴**
**归一化到一个数组内，看对应的这一秒如果不够了，预支下一秒的令牌数，并且让当前的线程睡眠**；
如果当前线程睡眠成功，下一秒唤醒的时候令牌也会扣掉，程序也实现了限流

```java
private RateLimiter orderCreateRateLimiter;

@PostConstruct
public void init(){
    executorService = executorService = new ThreadPoolExecutor(
        20,30,1L,TimeUnit.SECONDS,
        new LinkedBlockingQueue<>(10),Executors.defaultThreadFactory(),
        new ThreadPoolExecutor.AbortPolicy()
    );

    orderCreateRateLimiter = RateLimiter.create(300);
}
```

请求`createOrder`接口之前，会调用`RateLimiter.tryAcquire`方法，看当前令牌是否足够，不够直接抛出异常。

```java
if (!orderCreateRateLimiter.tryAcquire())
     throw new BusinessException(EmBusinessError.RATELIMIT);
```



#### 4、防刷技术

- 排队，限流，令牌均只能控制总流量，无法控制黄牛流量

**传统防刷**

- 限制一个会话（session_id，token）同一秒/分钟接口调用多少次：多会话接入绕开无效（黄牛开多个会话）
- 限制一个ip同一秒钟/分钟 接口调用多少次：数量不好控制，容易误伤，黑客仿制ip

**黄牛为什么难防**

- 模拟器作弊：模拟硬件设备，可修改设备信息
- 设备牧场作弊：工作室里一批移动设备
- 人工作弊：靠佣金吸引兼职人员刷单

**设备指纹**

- 菜鸡终端设备各项参数，启动应用时生成唯一设备指纹
- 根据对应设备指纹的参数猜测出模拟器等可疑设备概率

**凭证系统**

- 根据设备指纹下发凭证
- 关键业务链路上带上凭证并由业务系统到凭证服务器上验证
- 凭证服务器根据对应凭证所等价的设备指纹参数并根据实时行为风控系统判定对应凭证的可疑度分数
- 若分数低于某个数值则由业务系统返回固定错误码，拉起前端验证码验身，验身成功后加入凭证服务器对应分数

## 7、项目知识点图

![image-20211122114003198](https://gitee.com/huangwei0123/image/raw/master/img/image-20211122114003198.png)

